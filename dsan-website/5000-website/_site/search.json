[
  {
    "objectID": "data_cleaning/data_cleaning.html",
    "href": "data_cleaning/data_cleaning.html",
    "title": "Data Cleanning",
    "section": "",
    "text": "The purpose of data cleansing is to remove data noise points by eliminating erroneous, duplicate parts of the data. In this part, I will do a statictal analysis first to identify the dataset’s mean, variance, frenquency, etc. From this step, we can find the datasets’ noise points and clean them as needed. For the record data, most data cleaning process will dealing with the abnormal values, fill null values and remove missing values, etc. For the text data, most data cleaning process will dealing with cleaning the stop words, removing white spaces, etc."
  },
  {
    "objectID": "ARM/ARM.html",
    "href": "ARM/ARM.html",
    "title": "DSAN-5000: Project",
    "section": "",
    "text": "ARM"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN-5000: Introduction",
    "section": "",
    "text": "See the following link for more information about the author: about me"
  },
  {
    "objectID": "index.html#topics-introduction-financial-fraud-detection",
    "href": "index.html#topics-introduction-financial-fraud-detection",
    "title": "DSAN-5000: Introduction",
    "section": "1. Topics Introduction: Financial Fraud Detection",
    "text": "1. Topics Introduction: Financial Fraud Detection\n\nsummary: There are many type of financial fraud, credit card fraud, identity theft, account takeover, payment fraud, insurance fraud, money laudering, etc.\nImportance: The financial institution need to collect data, for example, transaction data, account history, customers’ data, etc, to analyze and predict the financial fraud to avoid the financial fraud in the future.\nWhy the reader should continue: there are more and more new fraud methods came up, the past machine learning model might cannot apply to the new fraud methods.\nwhat work had done: The researchers had done many data collection, data preprocessing, and set up machine learning models to do the logistic regression, decision trees and random forest, etc. They also had done so many behavioral analysis to analyze transaction frequency, amount, time of day, etc.\nwhat are the “different points of views”/interpretations in the literature: There are many different points of views related to the financial fraud. From economic Perspective, they may analyze the costs of fraud prevention and the actual costs of fraud. From the data scientists’ perspective, they wish to focus more on using data-driving approaches to prevent fraud. There are also many other perspectives from different researchers.\nwhat exploring: In this area, we need to explore more about the relations between customers’ behavior and the fraud methods\ngoals and hypothesis: clean the data I collect and find some factors that impact the financial fraud and make a fraud detetction model."
  },
  {
    "objectID": "index.html#questions-to-address",
    "href": "index.html#questions-to-address",
    "title": "DSAN-5000: Introduction",
    "section": "2. 10 questions to address",
    "text": "2. 10 questions to address\n\nCan customer reviews and sentiment analysis on social media predict the market success of a new Apple product release?\nHow can we predict whether Apple’s products would be popular in the future?\nHow does Apple’s stock performed?\nWhat kind of electronic products can be seem as a good product to buy?\nWhat kind of models we can used to predict people’s attitude with reviews?\nCan we use machine learning to identify key factors that predict an Apple product’s popularity based on historical data?\nHow does the pricing of Apple products compare with competitors over time, and what is the impact on market share and consumer choice?\nWhat are the trends in iPhone sales over the last decade, and how do they correlate with product release cycles and feature enhancements?\nCan decision tree analysis help in identifying the most significant factors that lead to a successful Apple Store location?\nHow can we eliminate the unnecessary feature for predicting the Apple’s products"
  },
  {
    "objectID": "index.html#realated-articles",
    "href": "index.html#realated-articles",
    "title": "DSAN-5000: Introduction",
    "section": "3. Realated Articles",
    "text": "3. Realated Articles\n\nA comparative study of online consumer reviews of Apple iPhone across Amazon, Twitter and MouthShut platforms1\nAbstract\n\nThe purpose of the paper is to understand if the online consumer reviews differ across the review platforms over the internet. We aim to find the features of the reviews from various platforms and ultimately create a typology of the reviews for those platforms. We apply mixed methods including both quantitative and qualitative techniques to arrive at the conclusion. We find consumers share their views on the highest number of topics in the ecommerce website. Consumers share in-depth views, but on a limited number of topics in other dedicated review platforms. Social media falls somewhere in the middle among these two platforms. While looking into the contents, we could generate themes and meta-themes from these reviews. Based on these facts, we create a typology/ontology for reviews from these platforms and map the motives of reviewers from each platform into the meta-themes identified. Managers can use our findings to boost their online review strategy according to the platform of their interest.\n\n\n\nThe influence of brand popularity, perceived quality, price, and need on purchase intention iPhone products in Purwokerto2\nAbstract\n\nThis study is a survey research that aims to determine and analyze the effect of brand popularity, perceived quality, price, and need on purchase intentions on iPhone products at Purwokerto city. The sample size in this study amounted to 120 using purposive sampling technique. Based on the results of data processing, it is known that brand popularity has no significant and negative effect on purchase intention. Price has a significant and negative effect on purchase intention. Perceived quality and need have a significant and positive effect on purchase intention. The findings in this study are that popularity is not always a consumer factor in generating purchase intentions, while the factor that has the greatest influence on purchase intentions is need."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "DSAN-5000: Introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nKundu, Supratim, and Swapnajit Chakraborti. “A Comparative Study of Online Consumer Reviews of Apple IPhone across Amazon, Twitter and MouthShut Platforms.” Electronic Commerce Research, vol. 22, no. 3, 2022, pp. 925–50, https://doi.org/10.1007/s10660-020-09429-w.↩︎\nRizaldi, Herna. ” The influence of brand popularity, perceived quality, price, and need on purchase intention iPhone products in Purwokerto.” Jurnal Akuntansi, Manajemen dan Ekonomi [Online], 24.2 (2022): 14-22. Web. 7 Nov. 2023↩︎"
  },
  {
    "objectID": "decision_trees/decision_trees.html",
    "href": "decision_trees/decision_trees.html",
    "title": "Introduction",
    "section": "",
    "text": "Decision Trees\n\nIntroduction\nA tree structure that describes instance classification is called a classification decision tree model. The nodes and directed edges create a decision tree. Inner nodes and leaf nodes are the two distinct types of nodes. Leaf nodes indicate a class, while internal nodes represent as a feature or attribute. A decision tree, additionally referred to as a binary or multinomial tree, is a predictive analytical model displayed as a tree structure."
  },
  {
    "objectID": "data_gathering/data_gathering.html",
    "href": "data_gathering/data_gathering.html",
    "title": "Data Gathering",
    "section": "",
    "text": "For this project, the main point is finding people’s attitude towards Apple Products and evaluate what kind of mobile products would attract the public to purchase. Thus I need to find both text data to reflect people’s attitude towards Apple Products and record data to evaluate the products’ popularity and people’s buying willingness. Thus, I need search online to find either people’s comments towards Apple Products or the news’ reports related to Apple products. Also, I need to find some dataset to evaluate what kinds of mobile products that would be popular in the market, so when the new generation of Apple Products come out we can predict the new products’ popularity.\n\n\n\n\nNews API: Gathering news’ reports to reflect the public attitudes towards Apple products.\nNews Webpage: Collect more news reports to reflect the public attitudes\nWeibo: Crawl comments from the social media to see the users’ reaction to the new Apple Products\nYahoo! Finance: collect Apple’s recent stock performance and this also can reflect the apple products’ popularity.\nMobile phone ratings: trying to find a dataset that have ratings related to all different functions of the mobile phones and what their popularity with the mobile phones.\n\n\n\n\n\nPython\nR\nNews API\nDownloading Dataset\n\n\n\n\n\n\n\nPython, Web crawl\nDataset Collecrion: Weibo is a Chinese social platform that Chinese public sharing thoughts and post articles. There are 52 illion daily active users via that social media.I crawled data from Weibo to catch some hot posts about people’s reaction to the new publishion of Apple products. Most of the articles relected strong sentiments towards the products\nweibo data gathering code (python)\nraw data for weibo(python)\nsample raw data \nDataset Exaplaination: From the view of dataset, this is a text dataset and we can see the users’ ID and the publish dates and also the contents and commens(in Chinese).\n\n\n\n\n\nPython, News API\nDataset Collection: crawl data by using NewsAPI with Python and try to extract some key words from the news. The news API can help me to find the most updated articles related to the topics I am trying to search and based on the contens, I can analyze those text to see what’s the attitude of media towards the iPhone.\nNews data gathering code (python)\nraw data for newsAPI(python)\nsample raw data \nDataset Exaplaination: As shown above, this is a text dataset and we can read all the articles that News API collected.\n\n\n\n\n\nR, Rvest\nDataset Collection: Revest is also an useful tool to help up to crawl conetent from the website we want. I used Rvest to craw text with R and get content from the news website I selected.\nNews webpage data gathering code (R)\nraw data for news webpage(R)\nsample raw data \nDataset Exaplaination: as shown in above, as shown above, this is also a text dataset and we can read all the articles that Rvest collected.\n\n\n\n\n\nDownloading from Yahoo! Finance\nDataset Collection: Stock price and trend also can reflect the company’s popularity and how the public’s attitude towards the company. Thus I downloaded the Apple stock’s recent stock price and trying to analyze its stock trend.\nDataset source: Apple Stock in Yahoo! Finance\nsample raw data \nDataset Explaination: As shown in the dataset, this is a record dataset. We can see there’s the date, Openprice, highest price, lowest Price, close price, and trading volume. Based on this dataset, for nect next step we can analyze its stock prices changes.\n\n\n\n\n\nCollecting from Dxomark\nDataset collection: The dataset that evaluate the functions for a mobile phone can help me to identify the public’s buying willingness to the product. Thus I collected the dataset from the DXOMARK website that reflect the device’s performance and the quality of the user experience.\nDataset source: DXOMARK smartphone reviews\nsample raw data \nDataset Explaination: As shown in the dataset, this is a record dataset. The dataset has its ranking and devices’ name, its Launch price, Launche date, camera rating, selfie rating, audio rating, display rating and battery ratings. All those ratings are important factors that impact the customers’ buying inetent. Thus this dataset will help me to predict wether a smartphone product will be popular based on the ratings.\n\n\n\n\nIn this part, I collected 5 different datasets that related to my research topic, Apple Products’ Popularity. The datasets are including text data and record data. The methods I used to collect data are using news API, crawling data with Python, Rvest with R, and downloading related data directly from the website.\nNext step I will clean and modified the data as need for preparing for the future model training."
  },
  {
    "objectID": "eda/eda.html",
    "href": "eda/eda.html",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "In this part, I will use visualization tools to help the audience know more about my project, which will include text clouds, statistic distribution, correlation heatmap, etc. This will help the audience to understand the general partterns in the data, and analysis the data.\n\n\n\n\n\n\n\nIn this text dataset, the type for this dataset is categorical data.\n\n\n\n\n\ncode in the news_cleanning.ipynb\n\n\n\n\nExplaination: After I cleaned the data with Numpy and Pandas package as I needed, I use the Wordcloud package to output the most frequent appeared words in those articles.\n\n\n\ntext cloud for news articles\n\n\n\n\n\n\n\n\nExplaination: I cleared out all the stopwords as needed, and get the most frequent words out to see the correlation between those key words. We can see that the color of words more close to white is more positive related, and the color more close to black is negative related. I used\n\n\n\ncorrelation heatmap for news articles\n\n\n\n\n\n\n\nfrom the analysis from above, we can see most of the key words from the news are positive or natural, which means, the public has postive attitude towards apple products.\n\n\n\n\n\n\n\n\nFor this dataset, it’s all numerical data. The open/close price are closely relate to each other\ncode in the code/EDA/apple_stock.ipynb file\n\n\n\n\n\n\n\n\nstatistics for apple stock\n\n\nAs shwon in the table, we can the standard deviation for the apple stock is around 19, it show a floating with the apple stock within days.\nhowever the max and min are similar for each open/close price, shows a stable status for the apple stock.\n\n\n\n\n\n\n\nExplaination: I collected the dataset of stock price from Yahoo! finance, and used Matplotlib, plotly and seaborn to plot the stock price in line plot with the open price and the date.\n\n\n\nopen price for apple stock\n\n\nWe can see from this plot that the price is in the increasing trend, which means the apple stock are more popular.\n\n\n\n\n\nExplaination: I collected the dataset of stock price from Yahoo! finance, and used Matplotlib, plotly and seaborn to plot the stock trading volume in each date in line plot\n\n\n\nopen price for apple stock\n\n\nAs shown, we can see the trading volume are decreasing during the time, which may indicate that the apple’s stock are less people buying, and it may related to the price.\n\n\n\n\n\n\n\n\n\nOutliers for apple stock\n\n\nAs shown, there’s no outliers for this stock, so, every points can be inclued in evaluating this data.\n\n\n\n\n\nfrom the analysis from above, we can see the apple stock price is still increasing, and seems still be popular to the public. This may indicate the Apple product is still popular in the market.\n\n\n\n\n\n\n\n\nFor this dataset, below are their data type.\n\n\n\nMobile Phone data type\n\n\nThe launch price, camera, selfie, audio, display, battery ratings are all related to the reank.\n\n\n\n\n\n\n\n\n\n\nThe relation of Launch Price and Buing Intent\n\n\nused Seaborn\nIt shows that the launch price actually determined whether willing to buy. When the price is around 750-1250 dollars, people are very willing to buy.\n\n\n\n\n\n\n\n\nThe relation between Buying Intent and Camera Rating\n\n\nused Seaborn\nIt also shows people willingness to buy are connected to the camera’s quality. the camera score that people very willing to buy is around 130-160 range.\n\n\n\n\n\n\n\n\nTop 50 Ranking Brands\n\n\nused Matplotlib\nAs shown in the graph, there are 20% Top 50 ranking phones are apples. Which shows, Apple is still one of the most popular brands in the market.\n\n\n\n\n\n\n\n\n\nThe correlation between features\n\n\nUsed heatmap\nIt semmed that camera and launch price are correlated to each other. And the Launch price camera score and audio score are negatively correlated to each other.\n\n\n\n\n\n\n\n\nstatistics for mobile phone\n\n\nthe mean Launch price is around $773.5 and the mean score for selfie is around 130, which is obviously higher than others (this is becuase I used mean to insert missing value)\n\n\n\n\n\nfrom the analysis we can analyze what kind of features would be popular around customers. This can be used for analysis whether apple would be best product among choices. It still prove that Apple is popular among customers.\n\n\n\n\n\n\n\n\nThis is a text record data, and it is a categorical data.\n\n\n\n\n\nfrequency distribution\n\n\n\nIphone 11 ratings\n\n\nUsed Seabron\nFrom the graph, we can see most people give 5.0 ratings, which shows that most customers satisfied the apple products\n\n\n\n\n\n\n\n\nstatistics for Ipohone11 ratings\n\n\nThe mean rating is 4.48 which is very high, shows that everyone like iphone 11\n\n\n\n\n\nfrom the analysis we can analyze that most customers satisfied apple’s products, so apple may be still popular in the market."
  },
  {
    "objectID": "eda/eda.html#quick-look-at-the-data",
    "href": "eda/eda.html#quick-look-at-the-data",
    "title": "Data Exploration",
    "section": "Quick look at the data",
    "text": "Quick look at the data\n\n# Import seaborn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Apply the default theme\nsns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n\n# Load an example dataset\ntips = sns.load_dataset(\"tips\")\nprint(tips)\n\n     total_bill   tip     sex smoker   day    time  size\n0         16.99  1.01  Female     No   Sun  Dinner     2\n1         10.34  1.66    Male     No   Sun  Dinner     3\n2         21.01  3.50    Male     No   Sun  Dinner     3\n3         23.68  3.31    Male     No   Sun  Dinner     2\n4         24.59  3.61  Female     No   Sun  Dinner     4\n..          ...   ...     ...    ...   ...     ...   ...\n239       29.03  5.92    Male     No   Sat  Dinner     3\n240       27.18  2.00  Female    Yes   Sat  Dinner     2\n241       22.67  2.00    Male    Yes   Sat  Dinner     2\n242       17.82  1.75    Male     No   Sat  Dinner     2\n243       18.78  3.00  Female     No  Thur  Dinner     2\n\n[244 rows x 7 columns]"
  },
  {
    "objectID": "eda/eda.html#basic-visualization",
    "href": "eda/eda.html#basic-visualization",
    "title": "Data Exploration",
    "section": "Basic visualization",
    "text": "Basic visualization\n\n\n# Create a visualization\nsns.relplot(\n    data=tips,\n    x=\"total_bill\", y=\"tip\", col=\"time\",\n    hue=\"smoker\", style=\"smoker\", size=\"size\",\n)\n\nplt.show()"
  },
  {
    "objectID": "clustering/clustering.html",
    "href": "clustering/clustering.html",
    "title": "Methods & Codes",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf=pd.read_csv(\"../../../data/01-modified-data/after_clean_mobile_phone_rating.csv\")"
  },
  {
    "objectID": "dimensionality_reduction/dimensionality_reduction.html",
    "href": "dimensionality_reduction/dimensionality_reduction.html",
    "title": "DSAN-5000: Project",
    "section": "",
    "text": "Dimensionality Reduction"
  },
  {
    "objectID": "conclusion/conclusion.html",
    "href": "conclusion/conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "The goal for this project is identify whether Apple products are still popular in the market, and find out public’s reaction to Apples’ new products. Also, I want to find out what kind of of quality of a mobile phone should have that will attract the public to buy. Thus, I should train some models that can predict a product’s populariy based on its functions, so when iPhone’s new generation came out, I can use thid model to predict its popularity.\n\n\n\n\n\nIn this part, I collected 3 text datasets and 2 record datasets by using API, Web Crawling, downloading methods by using Python and R. Most text datasets are related to the public’s reviews and comments towards Apple products,and one of the record datasets are related to Apple stock, and another is related to the mobile phones’ function rating. All the datasets can help me to dig into this research topic.\nHere’s some sample raw datasets:\nraw text data \nraw record data \n\n\n\nIn this part, I did data cleanning process for the datasets that I needed for preparing for future data analysis and model training. For the record data, I did fill null values, remove duplicates, handling outliers, convert data types, etc cleaning process. For the text data, I did remove stop words, remove special characters and punctuation, tokenization, stemming and lemmatization, remove white spaces, etc cleaning process.\nHere’s some sample cleaned datasets:\ncleaned text data \ncleaned record data \n\n\n\nIn this part, I did some exploratory data analysis for the cleaned datasets for better knowing the datasets. I used visualization tools to help the audience know more about my project, which will include text clouds, statistic distribution, correlation heatmap, etc.\nHere are some examples: \nHere’s some key words that appeared most frequently in the news dataset that I collected. As we can see, most words are natural and positive towards apple products.\n\n\n\nopen price for apple stock\n\n\nFrom the Apple stock’s plot we can see from the past year, the stock price is in the increasing trend, which means more poeple are willing to buy Apple’s stock, which means Apple is still popular in the market.\n\n\n\nTop 50 Ranking Brands\n\n\nAs shown in the pie chart, in the Top 50 ranking phones, 20% are apples. Which means there are 10 iphones are ranked in top50. This also shows Apple is still one of the most popular brands in the market.\n\n\n\nIn this part, I used K-means, DBSAN, Hierarchical clustering methods to clustered the mobile phone ratings dataset. Based on the hyperparameter turning, here’s the optimal clusters results: K-means: 2 DBSCAN : 4 Agglomerative Hierarchy: 2 Meanshift : 4 Birch : 3\nBased on the analysis process, I think Agglomerative Hierarchy would the best method for this dataset, and the optimal clustering would be 2.\n\n\n\nAgglomerative Hierarchy Clustering\n\n\n\n\n\nIn this part, I used PCA and t-SNE method to reduce the dimension for better analyzing the mobile phone ratings dataset. Based on the visualization result, I believe PCA would be a better method for this dataset.\n\n\n\nPCA\n\n\nAs shown in the graph, the red line intersect the blue line at number of comonents around = 4. So, when the number of compnents is larger than 4 which is 5, we can make 95% variance expliained. There for we should reduce the number of components to 5.\n\n\n\n\n\n\nIn this part, I used decision tree and random forest to do the classification. I training the model based on the mobile phone prices, the function ratings of the mobile phones to predict the public’s the buying intent to the products. - Decision Tree The optimal levels are 3\n\n\n\nDecision tree\n\n\nAnd the final test showed the model performed well: ACCURACY: 0.967741935483871 NEGATIVE RECALL (Y=0): 1.0 NEGATIVE PRECISION (Y=0): 0.9375 POSITIVE RECALL (Y=1): 0.9375 POSITIVE PRECISION (Y=1): 1.0 \n\nRandom Forest The result for the random forst is similar to the decision tree, and I believe the decision tree is better predict the model. More content related to random forest can be found in the Decision Tree Tab.\n\n\n\n\nIn this part, I used Naive Bayes algorithmn predict the lebels for the mobile phone ratings dataset and also the news text dataset. I used feature selection of variance thredhold method with hyperparameter tuning for better training the model.\nFinal result showed the naive bayes predicted my record dataset well. \n\n\n\nConfusion Metrics\n\n\nFinal result also showed the naive bayes predicted my text dataset well.\n\n\n\nEvaluation Metrics\n\n\n\n\n\nConfusion Metrics\n\n\nMore analysis can find in the Naive Bayes tab.\n\n\n\n\nBased on the research above, I belive I can explain all the questions listed in the introduction well:\n\nCan customer reviews and sentiment analysis on social media reflect the public’s reaction to the products?\nYes, based on the sentiment analysis and key words extraction, we can see the public’s reaction easily.\nHow does Apple’s stock performed? Apple stock performed well in the past year.\nWhat are the trends in iPhone stocks sale volume over the last decade? the sale volumn are not increasing that much which may be a good signal for the current shareholder.\nWhat kind of electronic products can be seem as a good product to buy? higher in price, higher in the selfie, audio, etc functions ratings.\nHow does the pricing of Apple products compare with competitors over time, and what is the impact on market share and consumer choice? Apple’s product are kind of higher than the other competitors’ products\nHow can we predict whether Apple’s products would be popular in the future? From its function ratings, we can predict whether the public willing to buy or not.\nCan we use machine learning to identify key factors that predict an Apple product’s popularity based on historical data? Yes, based on the correlation map, we can see the price and selfie function are highly corelated and impacted the products’ popularity\nWhat kind of models we can used to predict people’s attitude with reviews? we can use the naive bayes or decision tree model to predict\nCan decision tree analysis help in identifying whether a product is a successful mobile phone product? Yes, we can use decision tree actually is the best method to predict the label.\nHow can we eliminate the unnecessary feature for predicting the Apple’s products? We can use some feature selection methods, like variance thredhold to eliminate some features.\n\n\n\n\nFrom this project, we can know more about the public’s review and reaction on apple products and how to predict a new generation iphone’s popularity. From all the research above, I can conclude that Apple products are still popular in the market, and people’s reviews are more in postive way. The Apple stock price also reflect the popularity of Apple brand. Also the ratings of apple products are still very high compare to other brands.\nThus, apple products are still very popular and worthy to buy based on its functionality ratings. We can also use those ratings based on machine learning models to predict the popularity of future products.\nThanks for going over this project!"
  },
  {
    "objectID": "eda/eda.html#introduction-to-eda",
    "href": "eda/eda.html#introduction-to-eda",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "In this part, I will use visualization tools to help the audience know more about my project, which will include text clouds, statistic distribution, correlation heatmap, etc. This will help the audience to understand the general partterns in the data, and analysis the data."
  },
  {
    "objectID": "eda/eda.html#news-articles-dataset",
    "href": "eda/eda.html#news-articles-dataset",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "In this text dataset, the type for this dataset is categorical data.\n\n\n\n\n\ncode in the news_cleanning.ipynb\n\n\n\n\nExplaination: After I cleaned the data with Numpy and Pandas package as I needed, I use the Wordcloud package to output the most frequent appeared words in those articles.\n\n\n\ntext cloud for news articles\n\n\n\n\n\n\n\n\nExplaination: I cleared out all the stopwords as needed, and get the most frequent words out to see the correlation between those key words. We can see that the color of words more close to white is more positive related, and the color more close to black is negative related. I used\n\n\n\ncorrelation heatmap for news articles\n\n\n\n\n\n\n\nfrom the analysis from above, we can see most of the key words from the news are positive or natural, which means, the public has postive attitude towards apple products."
  },
  {
    "objectID": "eda/eda.html#apple-stock-dataset",
    "href": "eda/eda.html#apple-stock-dataset",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "For this dataset, it’s all numerical data. The open/close price are closely relate to each other\ncode in the code/EDA/apple_stock.ipynb file\n\n\n\n\n\n\n\n\nstatistics for apple stock\n\n\nAs shwon in the table, we can the standard deviation for the apple stock is around 19, it show a floating with the apple stock within days.\nhowever the max and min are similar for each open/close price, shows a stable status for the apple stock.\n\n\n\n\n\n\n\nExplaination: I collected the dataset of stock price from Yahoo! finance, and used Matplotlib, plotly and seaborn to plot the stock price in line plot with the open price and the date.\n\n\n\nopen price for apple stock\n\n\nWe can see from this plot that the price is in the increasing trend, which means the apple stock are more popular.\n\n\n\n\n\nExplaination: I collected the dataset of stock price from Yahoo! finance, and used Matplotlib, plotly and seaborn to plot the stock trading volume in each date in line plot\n\n\n\nopen price for apple stock\n\n\nAs shown, we can see the trading volume are decreasing during the time, which may indicate that the apple’s stock are less people buying, and it may related to the price.\n\n\n\n\n\n\n\n\n\nOutliers for apple stock\n\n\nAs shown, there’s no outliers for this stock, so, every points can be inclued in evaluating this data.\n\n\n\n\n\nfrom the analysis from above, we can see the apple stock price is still increasing, and seems still be popular to the public. This may indicate the Apple product is still popular in the market."
  },
  {
    "objectID": "eda/eda.html#iphone_11_review_dataset",
    "href": "eda/eda.html#iphone_11_review_dataset",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "This is a text record data, and it is a categorical data.\n\n\n\n\n\nfrequency distribution\n\n\n\nIphone 11 ratings\n\n\nUsed Seabron\nFrom the graph, we can see most people give 5.0 ratings, which shows that most customers satisfied the apple products\n\n\n\n\n\n\n\n\nstatistics for Ipohone11 ratings\n\n\nThe mean rating is 4.48 which is very high, shows that everyone like iphone 11\n\n\n\n\n\nfrom the analysis we can analyze that most customers satisfied apple’s products, so apple may be still popular in the market."
  },
  {
    "objectID": "eda/eda.html#mobile_phone_rating-dataset",
    "href": "eda/eda.html#mobile_phone_rating-dataset",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "For this dataset, below are their data type.\n\n\n\nMobile Phone data type\n\n\nThe launch price, camera, selfie, audio, display, battery ratings are all related to the reank.\n\n\n\n\n\n\n\n\n\n\nThe relation of Launch Price and Buing Intent\n\n\nused Seaborn\nIt shows that the launch price actually determined whether willing to buy. When the price is around 750-1250 dollars, people are very willing to buy.\n\n\n\n\n\n\n\n\nThe relation between Buying Intent and Camera Rating\n\n\nused Seaborn\nIt also shows people willingness to buy are connected to the camera’s quality. the camera score that people very willing to buy is around 130-160 range.\n\n\n\n\n\n\n\n\nTop 50 Ranking Brands\n\n\nused Matplotlib\nAs shown in the graph, there are 20% Top 50 ranking phones are apples. Which shows, Apple is still one of the most popular brands in the market.\n\n\n\n\n\n\n\n\n\nThe correlation between features\n\n\nUsed heatmap\nIt semmed that camera and launch price are correlated to each other. And the Launch price camera score and audio score are negatively correlated to each other.\n\n\n\n\n\n\n\n\nstatistics for mobile phone\n\n\nthe mean Launch price is around $773.5 and the mean score for selfie is around 130, which is obviously higher than others (this is becuase I used mean to insert missing value)\n\n\n\n\n\nfrom the analysis we can analyze what kind of features would be popular around customers. This can be used for analysis whether apple would be best product among choices. It still prove that Apple is popular among customers."
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html",
    "href": "Naive_Bayes/Naive_Bayes.html",
    "title": "Introduction to Naive Bayes:",
    "section": "",
    "text": "The process of training the Naive Bayes algorithm is actually the process of solving each a priori probability P(Ai) and conditional probability P(Bj|Ai), and then in the prediction and classification process, it is only necessary to substitute each probability value obtained during the training process into the Bayesian formula, so as to obtain the relative probability of the results of the classification labels under the current features. The one with higher relative probability is naturally used as the predicted label.\n\n\n\n\n\n\\(P(Y|X) = (P(X|Y) * P(Y))/P(X)\\)\nP(A|B) is called the a posteriori probability, for the target to be found\nP(A) is the a priori probability, which can be statistically derived from a large amount of data, or empirically provided when the amount of data is small.\nP(B|A) is the conditional probability, which can be statistically derived from a large amount of data, and is usually given by great likelihood estimation, and is actually also the a priori probability\n\n\n\n\n\nGaussian Naive Bayes: This variant of Naive Bayes is best suited for datasets where the features are continuous and follow a Gaussian or normal distribution. It assigns a Gaussian distribution to each class and predicts the class of a new data point based on these distributions. Common applications include problems that involve continuous variables, as is often found in real-world datasets.\nMultinomial Naive Bayes: This type excels with discrete data and finds frequent application in text categorization tasks, where text is converted into word frequency vectors. However, it can also work with tf-idf vectors. It computes the conditional probability of a word given a class, making it a good choice for problems involving discrete data.\nBernoulli Naive Bayes: This method is ideal for binary or boolean features and is typically used in text classification tasks where the presence or absence of a word is more important than its frequency. It assumes that all our features are binary-valued and models the input data with a multivariate Bernoulli distribution.\n\n\n\n\nI will use Naive Bayes Algorithmn to train 2 datasets, the objective for using this is for accurately predicting the lebels for my datasets:\n\nMobile phone rating: This is a record dataset. There are features like mobiles camera scores, audio scores, display scores, etc, and those related to the customers’ willingness to buy this phone or not. The main goal for training this dataset is for repeict customer’s willingness to buy a phone or not depends on those feature scores.\nIphone 11 reviews: This is a text dataset. The text are customers reviews. The main goal for this data training is by through the reviews, predict the attitutes of the customers."
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html#introduction-to-naive-bayes",
    "href": "Naive_Bayes/Naive_Bayes.html#introduction-to-naive-bayes",
    "title": "DSAN-5000: Project",
    "section": "",
    "text": "The process of training the Naive Bayes algorithm is actually the process of solving each a priori probability P(Ai) and conditional probability P(Bj|Ai), and then in the prediction and classification process, it is only necessary to substitute each probability value obtained during the training process into the Bayesian formula, so as to obtain the relative probability of the results of the classification labels under the current features. The one with higher relative probability is naturally used as the predicted label.\n\n\n\n\n\n\\(P(Y|X) = (P(X|Y) * P(Y))/P(X)\\)\nP(A|B) is called the a posteriori probability, for the target to be found\nP(A) is the a priori probability, which can be statistically derived from a large amount of data, or empirically provided when the amount of data is small.\nP(B|A) is the conditional probability, which can be statistically derived from a large amount of data, and is usually given by great likelihood estimation, and is actually also the a priori probability"
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html#prepare-dataset",
    "href": "Naive_Bayes/Naive_Bayes.html#prepare-dataset",
    "title": "Introduction to Naive Bayes:",
    "section": "Prepare Dataset",
    "text": "Prepare Dataset\n\ncreate labels\nI create labels for the mobile phone by its rankings\n(code in codes/data-cleaning/mobile_phone_rating.ipynb).\n\nThe top 50 ranking phones is Very Willing\nThe 51-100 ranking phones is Moderately Willing\nThe 101-last ranking ophones is Not Willing\n\n\n\nSplit data\n(code in codes/naive_bayes/mobile_phone_rating_training)\n\nI split data into traning set 70%, validation set 15%, and test set 15%.\n70% in training will increase the accuracy for the model learning. And the rest each 15% for better identify the training results."
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html#feature-selection",
    "href": "Naive_Bayes/Naive_Bayes.html#feature-selection",
    "title": "Introduction to Naive Bayes:",
    "section": "Feature Selection",
    "text": "Feature Selection\n(code in codes/naive_bayes/mobile_phone_rating_training)\nAccording to the number of features, I found out it nearly has no impact on the trainig. - \nThus I chose to use Vairance Thredhold for this data, after the selection, I find out the optimal thredhold. It turns out the optimal thredhold is 26.51, and the accuracy is around 88%."
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html#naive-bayes-with-labeled-record-data",
    "href": "Naive_Bayes/Naive_Bayes.html#naive-bayes-with-labeled-record-data",
    "title": "Introduction to Naive Bayes:",
    "section": "Naive Bayes with Labeled Record Data",
    "text": "Naive Bayes with Labeled Record Data\n(code in codes/naive_bayes/mobile_phone_rating_training)\n\nHowever, after I tried several times for selecting the vairance thredhold, becuase the feature selection process above elimiating some cornor cases, but there are not that many features in my model, if i eliminating them, it would decrease my model accuracy. So after all, I found the optimal thredhold should be 45, so I choose to use that for my model.\nIn that way, the ‘Selfie’ column will be deducted, which make sense because when I did data cleaning process, there are many nulls and I use the mean to fill null.\n\n\nfinal result\n\nEvaluation Matrices\n\n\n\n\nEvaluation Metrics\n\n\nAs shown above, the accuracy of my model is 91.3% and which is very high, shows it’s a good model.\nPrecision is comparely low for the “not will”, but it’s ok, since the number of that labels are not too many.\nF-1 score and recall performs well.\nMacro Avg: Precision: 86%, Recall: 94%, F1-Score: 89% are all very high schore, shows it’s a good model to fit in.\nWeighted Avg: Precision: 93%, Recall: 91% , F1-Score: 92%, shows it’s a good model to fit in.\nIt did not show any overfitting or underfitting,since the test scores perform well.\n\n\n\nconfusion matrices\n\n\n\n\nConfusion Metrics\n\n\nAs shown above, the accuracy for predicting labels are very high. Only 2 labels are inaccurately predicted."
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html#conclusion",
    "href": "Naive_Bayes/Naive_Bayes.html#conclusion",
    "title": "Introduction to Naive Bayes:",
    "section": "Conclusion",
    "text": "Conclusion\nThe model predict my dataset well. After he variance Thredhold feature selection, the accuracy increased from about 88% to 91.3%. Also, the model did not show overfitting/underfitting because of its traning accuracy and test accuracy are all around 90%. Thus this model can well predict how those scores impact people’s buying willingness."
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html#prepare-dataset-1",
    "href": "Naive_Bayes/Naive_Bayes.html#prepare-dataset-1",
    "title": "Introduction to Naive Bayes:",
    "section": "Prepare Dataset",
    "text": "Prepare Dataset\n\ncreate labels\nI create labels for the mobile phone by its ratings\n(code in codes/naive_bayes/iphone_11_review_training.ipynb).\n\nThe top 50 ranking phones is Very Willing\nThe 51-100 ranking phones is Moderately Willing\nThe 101-last ranking ophones is Not Willing\n\n\n\nSplit data\n(code in codes/naive_bayes/iphone_11_review_training.ipynb).\n\nI split data into traning set 80%, and test set 20%.\n80% in training will increase the accuracy for the text model learning. Also, 20% of test dataset is enough for giving good results."
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html#feature-selection-1",
    "href": "Naive_Bayes/Naive_Bayes.html#feature-selection-1",
    "title": "Introduction to Naive Bayes:",
    "section": "Feature Selection",
    "text": "Feature Selection\n(code in codes/naive_bayes/iphone_11_review_training.ipynb)\n\n\n\n\nfeature selection\n\n\nAs shown in the graph, when the number of features close to 600-700, the test and training accuracy score did not improve. And after that, the model indicate it’s overfitting because the taining accuracy is high but test accuracy is not that hight. So our opimal feature selection should around 600-700.\n\n\n\nrunning time\n\n\nAs shown in the graph, when the number of features close to 1000 the running time increased a lot\n\nBased on those observation, and also from the accuracy scores of each number of features, I get the optimal number of features are 640. With this feature number, the accuracy and running time are optimal."
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html#naive-bayes-with-labeled-text-data",
    "href": "Naive_Bayes/Naive_Bayes.html#naive-bayes-with-labeled-text-data",
    "title": "Introduction to Naive Bayes:",
    "section": "Naive Bayes with Labeled Text Data",
    "text": "Naive Bayes with Labeled Text Data\n(code in codes/naive_bayes/iphone_11_review_training.ipynb)\n\n\n\n\nEvaluation Metrics\n\n\nAs shown above, the accuracy of my model is 90.11% and which is very high, shows it’s a good model.\nMacro Avg: Precision: 65%, Recall: 58%, F1-Score: 61%, those scores are comparedly not perform very well, it is because some low performance for the natural(0) class, this is also make sense, because there are not many data related to that class.\nWeighted Avg: Precision: 89%, Recall: 90% , F1-Score: 89%, shows it’s a good model to fit.\n\n\nconfusion matrices\n\n\n\n\nConfusion Metrics\n\n\nAs shown above, the accuracy for predicting right labels are very high.\nIn total, 903 data labels were predicted accurately. The model predited well in the positive and negative classes, but did not perform well in the natural class. This is because there are not so many data of natural."
  },
  {
    "objectID": "Naive_Bayes/Naive_Bayes.html#conclusion-1",
    "href": "Naive_Bayes/Naive_Bayes.html#conclusion-1",
    "title": "Introduction to Naive Bayes:",
    "section": "conclusion",
    "text": "conclusion\nThe model predict my dataset well. After the number of features selection method, the accuracy can reach 90.11%. However, because the insufficient of data related to natural label class, the prediction to this class did not perform so well as expected.\nAlso, the model did not show overfitting/underfitting because of its traning accuracy and test accuracy are all around 90%.\nThus, overall the model performed well, and it can based on the text reviews predict poeple’s attitude towards iphone 11 products."
  },
  {
    "objectID": "index.html#topics-introduction-iphones-popularity-in-the-markey",
    "href": "index.html#topics-introduction-iphones-popularity-in-the-markey",
    "title": "DSAN-5000: Introduction",
    "section": "1. Topics Introduction: iPhone’s popularity in the markey",
    "text": "1. Topics Introduction: iPhone’s popularity in the markey\n\nsummary\nOver the decades, Apple’s products are always the most popular products in the markets. However, with more and more new products introduced to the market. Is Apple products, especially iphone, are still popular in the market?\nImportance\nThe iPhone has significantly influenced technology and culture since its introduction in 2007. It has influenced and impacted a genration, thus everyone curious about how apple performed in the recent years. Its role in shaping consumer behaviors, communication norms, and mobile technology makes it a rich subject for study.\nWhy the reader should continue\nThe choices and preferences of iPhone users can reflect broader trends in consumer behavior. Consumers can pick better products through this research topic and see how consumers react to Apple’s products.\nwhat work had done\nThe researchers had done many data collection, data preprocessing, and set up machine learning models to do the logistic regression, decision trees and random forest, etc. They also had done so many behavioral analysis to analyze the popularity trend for electronic products.\nwhat are the “different points of views”/interpretations in the literature\nSome literature emphasizes Apple’s commitment to innovation and high-quality products as a key factor in its popularity. This view holds that the company’s focus on design, user experience, and robust performance drives consumer preference. Some authors also discuss Apple’s cultural impact, suggesting that its products have become more than just technology but a part of modern culture.\nwhat exploring:\n\nWe can explore how people evaluate an electronic products as a good products.\nWe can explore the stock market for the Apple Products and how it stock prices changes\nWe can collect customers’ review/news on Apple products, to see how everyone like apple’s products.\n\ngoals and hypothesis\nclean the data I collect and find some factors that impact the financial fraud and make a fraud detetction model."
  },
  {
    "objectID": "clustering/clustering1.html",
    "href": "clustering/clustering1.html",
    "title": "Clustering",
    "section": "",
    "text": "In my Mobile Phone Rating Dataset, the features are including the ratings about the function of the mobile phones. There are 6 features, Launch Price, camera rating, selfie rating, audio rating, display rating, and battery rating.\nThe purpose of this clustering analysis is for doing the unsupervised learning to find out the possible clusters of the dataset and what is the optimal cluster number"
  },
  {
    "objectID": "clustering/clustering.html#k-means",
    "href": "clustering/clustering.html#k-means",
    "title": "Methods & Codes",
    "section": "K means",
    "text": "K means\n\n# for k means clustering we will use the elbow method to find the optimal number of clusters. we will use the inertia_ attribute to find the sum of squared distances of samples to their closest cluster center. we will use the range of 1 to 10 clusters. plot the inertia_ values for each number of clusters. make sure to save it in a dataframe and plot it using matplotlib.\ninertia = []\ndistortions = []\nfor num_clusters in range(1, 11):\n    kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n    kmeans.fit(X_normalized)\n    inertia.append(kmeans.inertia_)\n    distortions.append(sum(np.min(cdist(X_normalized,kmeans.cluster_centers_, 'euclidean'),axis=1)) /X_normalized.shape[0])\n\ndf_inertia = pd.DataFrame({'Number of Clusters': range(1, 11), 'Inertia': inertia})\ndf_distortions=pd.DataFrame({'Number of Clusters': range(1, 11), 'distortions': distortions})\n\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/sherryqin/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n# plot distortion and inertia for kmeans, you can either plot them seperately or use fig, ax = plt.subplots(1, 2) to plot them in the same figure. Suggest the optimal number of clusters based on the plot.\nplt.plot(df_inertia['Number of Clusters'], df_inertia['Inertia'], marker='o', linestyle='-')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Inertia')\nplt.title('Elbow Method for Optimal Number of Clusters')\nplt.grid(True)\nplt.show()\n\n\n\n\n\nplt.plot(df_inertia['Number of Clusters'], df_distortions['distortions'], marker='o', linestyle='-')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Distortions')\nplt.title('Elbow Method for Optimal Number of Clusters')\nplt.grid(True)\nplt.show()\n\n\n\n\nBy using K means algorithmn, we can see the inertia and distortion with different number of clusters by using hyper-parameter elbow methods. From the graphs above, it seemed that 2 is the optimal number of clusters for me dataset. However, it’s not that obious elbow can be shown from the graph."
  },
  {
    "objectID": "clustering/Results.html",
    "href": "clustering/Results.html",
    "title": "Results Analysis",
    "section": "",
    "text": "Optimal Clusters\n\n\nK-means: 2\nDBSCAN : 4\nAgglomerative Hierarchy: 2\nMeanshift : 4\nBirch : 3\n\n\nAnalysis I think the better method would be Agglomerative Hierarchy for the following reasons.\n\n\nIt’s easier for me to use, because I do not need to identify the k clusters before using it. It would automatically give me the optimal result.\nSince my dataset is not that big, so using agglomerative is more effective to my dataset.\nIt can also make me easily see the hierarchy relationships with my dataset.\nThe final result of the optimal clusters are 2 is making sense, because in my original dataset, I labeled them into 3 clusters and it turned out that for the “nature” cluster, there’s not that many dataset belongs to this cluster.\nCompared to K-means, as shown in the graphs of K-means, the elbow is not that obvious for me. Compared to DBSCAN and Meansift’s result, I think 4 clusters would make the clusters contained not enough data points.\nAfter observations, I believe the higher of the price and the other function rating features would be seperated into a cluster. And the lower of the price and the other function rating features would be seperated into another cluster."
  },
  {
    "objectID": "clustering/Results.html#different-methods-comparing",
    "href": "clustering/Results.html#different-methods-comparing",
    "title": "Results Analysis",
    "section": "",
    "text": "Optimal Clusters\n\n\nK-means: 2\nDBSCAN : 4\nAgglomerative Hierarchy: 2\nMeanshift : 4\nBirch : 3\n\n\nAnalysis I think the better method would be Agglomerative Hierarchy for the following reasons.\n\n\nIt’s easier for me to use, because I do not need to identify the k clusters before using it. It would automatically give me the optimal result.\nSince my dataset is not that big, so using agglomerative is more effective to my dataset.\nIt can also make me easily see the hierarchy relationships with my dataset.\nThe final result of the optimal clusters are 2 is making sense, because in my original dataset, I labeled them into 3 clusters and it turned out that for the “nature” cluster, there’s not that many dataset belongs to this cluster.\nCompared to K-means, as shown in the graphs of K-means, the elbow is not that obvious for me. Compared to DBSCAN and Meansift’s result, I think 4 clusters would make the clusters contained not enough data points.\nAfter observations, I believe the higher of the price and the other function rating features would be seperated into a cluster. And the lower of the price and the other function rating features would be seperated into another cluster."
  },
  {
    "objectID": "dimensionality_reduction/reduction.html",
    "href": "dimensionality_reduction/reduction.html",
    "title": "Dimensionality Reduction",
    "section": "",
    "text": "In this tab, I will try to use PCA and t-SNE method to reduce the dimension for better analyzing the mobile phone dataset."
  },
  {
    "objectID": "dimensionality_reduction/reduction.html#project-proposal",
    "href": "dimensionality_reduction/reduction.html#project-proposal",
    "title": "Dimensionality Reduction",
    "section": "",
    "text": "In this tab, I will try to use PCA and t-SNE method to reduce the dimension for better analyzing the mobile phone dataset."
  },
  {
    "objectID": "dimensionality_reduction/reduction.html#code",
    "href": "dimensionality_reduction/reduction.html#code",
    "title": "Dimensionality Reduction",
    "section": "Code",
    "text": "Code\n\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\n\nfrom sklearn.preprocessing import StandardScaler\n\n\ndf=pd.read_csv(\"../../../data/01-modified-data/after_clean_mobile_phone_rating.csv\")\n\n\nx=df[['Launch Price','CAMERA','SELFIE','AUDIO','DISPLAY','BATTERY']]\ny=df[['buying_intent']]\nscaler = StandardScaler()\nX = scaler.fit_transform(x)\n\n\nDimensionality Reduction with PCA\n\n# EIGEN VALUES/VECTOR\nfrom numpy import linalg as LA\n# w, v1 = LA.eig(cov)\nw, v1 = LA.eig(np.cov(X.T))\nprint(\"\\nCOV EIGENVALUES:\",w)\nprint(\"COV EIGENVECTORS (across rows):\")\nprint(v1.T)\n\n\nCOV EIGENVALUES: [2.46422101 1.21865397 0.24126397 0.958379   0.63183561 0.52512012]\nCOV EIGENVECTORS (across rows):\n[[ 0.50024701  0.53945186  0.20733577  0.42438368  0.44295301 -0.19861426]\n [ 0.39766903  0.19014289 -0.67810966 -0.25218719 -0.31386294 -0.42867702]\n [-0.69792826  0.69118266 -0.15187461 -0.05535362  0.03015126 -0.09013136]\n [ 0.21875576  0.21730996 -0.34121012 -0.27020298  0.26679962  0.8026869 ]\n [-0.19511955 -0.26042618 -0.57511145  0.73310744  0.13997149  0.07946605]\n [ 0.13631836  0.2829461   0.16412113  0.3778623  -0.78332594  0.34357475]]\n\n\n\n# PCA CALCULATION\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=6)\npca.fit(X)\nprint('\\nPCA')\nprint(pca.components_)\n\n\nPCA\n[[-0.50024701 -0.53945186 -0.20733577 -0.42438368 -0.44295301  0.19861426]\n [ 0.39766903  0.19014289 -0.67810966 -0.25218719 -0.31386294 -0.42867702]\n [ 0.21875576  0.21730996 -0.34121012 -0.27020298  0.26679962  0.8026869 ]\n [-0.19511955 -0.26042618 -0.57511145  0.73310744  0.13997149  0.07946605]\n [ 0.13631836  0.2829461   0.16412113  0.3778623  -0.78332594  0.34357475]\n [ 0.69792826 -0.69118266  0.15187461  0.05535362 -0.03015126  0.09013136]]\n\n\n\n# # PLOT\nv2=pca.components_\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\nax.scatter(X[:,0],X[:,1],X[:,2],marker=\".\", cmap=\"viridis\")\nv1=v1*1000\nv2=v2*1000\n\nax.quiver(0,0,0,v1[0,0],v1[1,0],v1[2,0])\nax.quiver(0,0,0,v1[0,1],v1[1,1],v1[2,1])\nax.quiver(0,0,0,v1[0,2],v1[1,2],v1[2,2])\n\nax.quiver(0,0,0,v2[0,0],v2[1,0],v2[2,0])\nax.quiver(0,0,0,v2[0,1],v2[1,1],v2[2,1])\nax.quiver(0,0,0,v2[0,2],v2[1,2],v2[2,2])\nplt.show()\n\n/var/folders/j3/s32rl54j1f76nvbcx9mxg4yc0000gn/T/ipykernel_92317/2939638508.py:5: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  ax.scatter(X[:,0],X[:,1],X[:,2],marker=\".\", cmap=\"viridis\")\n\n\n\n\n\n\nplt.figure(figsize=(8,4))\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.axhline(y=0.95, color='red', linestyle='--', linewidth=2, label='95% explained variance')\ncum_explained=np.cumsum(pca.explained_variance_ratio_)\noptimal_components = np.where(cum_explained &gt;= 0.95)[0][0]+1\nplt.axvline(x=optimal_components, color='red', linestyle='--', linewidth=2, label=f'Optimal components: {optimal_components}')\nplt.show()\n\n\n\n\n\n\nObersvation\nThe curve represents the cumulative explained variance as a proportion of the total variance by the number of components. The y-axis is Cumulative explained variance, and the x-aixs is number of compemonts. As shown, the cure is upward shift along with the increase of the number of components. The first component explains about more than 60% of the variance and the second component adds approximately 10% more to the explained variance, bringing the total to around 80%. However, the the added contribution decreased when the number of components increased. We want to find out the number of components that make 95% cummulative explained variance. Thus I made a red line when cummulative exmplained variance=0.95, and as shown in the graph, the red line intersect the blue line at number of comonents around = 4. So, when the number of compnents is larger than 4, we can make 95% variance expliained. This means the number of components that can make 95% cummulative explained variance is 5.\n\n\nDimensionality Reduction with t-SNE\n\nfrom sklearn.manifold import TSNE\n\n\n# 2D\ntsne = TSNE(n_components=2, perplexity=30, learning_rate=200, n_iter=1000)\nX_tsne = tsne.fit_transform(X)\nplt.scatter(X_tsne[:, 0], X_tsne[:, 1])\nplt.show()\n\n\n\n\n\n# 3D\ntsne = TSNE(n_components=3, perplexity=30, learning_rate=200, n_iter=1000)\nX_tsne = tsne.fit_transform(X)\n\n\nfig = plt.figure(figsize=(8, 6))\nax = fig.add_subplot(111, projection='3d')\n\nax.scatter(X_tsne[:, 0], X_tsne[:, 1], X_tsne[:, 2])\n\nax.set_xlabel('t-SNE Feature 1')\nax.set_ylabel('t-SNE Feature 2')\nax.set_zlabel('t-SNE Feature 3')\nplt.title('3D t-SNE Visualization')\nplt.show()\n\n\n\n\n\n#parameter tuning for t-SNE (perplexity)\nperplexities = [5, 25, 50]\nlearning_rates = [10, 200, 500]\n\nfig, axs = plt.subplots(len(perplexities), len(learning_rates), figsize=(15, 10))\n\nfor i, perplexity in enumerate(perplexities):\n    for j, learning_rate in enumerate(learning_rates):\n        tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=learning_rate, n_iter=1000)\n        X_tsne = tsne.fit_transform(X)\n        axs[i, j].scatter(X_tsne[:, 0], X_tsne[:, 1])\n        axs[i, j].set_title(f'Perplexity: {perplexity}, Learning Rate: {learning_rate}')\n\nplt.show()\n\n\n\n\n\n\nObservation\nPerplexity: This t-SNE parameter influences how well the local and global components of your data are balanced. Learning Rate: This variable also affects how well the algorithm matches the data. It can be represented as the size of the step that the algorithm uses to discover the representation. As shown in the graph: * Perplexity = 5 with learning rate increasing, the points become denser, which indicating a better balance between local and global perspective. * Perplexity = 25 with learning rate increasing, the points become denser. When the learning rate=200, the structure is more obvious. However when learning rate reach 500, the points are too dense, which may refelct the learning rate may be too high. * Perplexity = 50 with learning rate increasing, the points become denser as well, but not show the structure clearly, so it may not a good fit.\nFrom the observation above, I believe the perplexity=25-50 and learning rate=20 might be the best balance for visualizing the data structure.\nHowever, Compared to PCA, I think t-SNE is less practical to this dataset than PCA because the structure of pattern of t-SNE for this dataset is not so easy to recognize."
  },
  {
    "objectID": "dimensionality_reduction/reduction.html#project-report---evaluation-and-comparasion",
    "href": "dimensionality_reduction/reduction.html#project-report---evaluation-and-comparasion",
    "title": "Dimensionality Reduction",
    "section": "Project Report - Evaluation and comparasion",
    "text": "Project Report - Evaluation and comparasion\n\nPCA\nStrength:\n\nPCA can be both used in the small, simple constructed dataset and large complicated dataset.\nIt reduce the noise in the dataset\npreserve the global structure\nworks well with linear dimensionality reduction\n\nWeakness:\n\ndoes not involve hyperparameter tuning\nOversimplification of the data\nloss of valuable information\n\n\n\nt-SNE\nStrength:\n\ninvolve hyperparameters tuning\nPreserves Local and Global Structure\n\nWeakness:\n\nWhen we are trying to reducing the dimension, the distance between points in low dimension are actually not match with the actual distance of the high dimension\nIn the high dimension, if the distance between points are large, but when we convert to low dimension, the distance may be smaller.\nIt is computationally intensive and may not scale well to extremely large datasets 1\n\n\n\nConclusion\nIf the dataset is more linear and dataset size is small, using PCA would be better.\nIf the dataset is not linear and the dataset size is large, using t-SNE would be better.\nI think PCA is better to use in this dataset because from the plot of t-SNE, it’s really hard to recognize the pattern, but from the result of PCA, we can easity find out how many components we want to keep. So, this dataset may be more in linear relationship. Also, my dataset is not large, so it’s better to use PCA over t-SNE.\nIn conclusion, when we doing the dimensionality recution process, it’s important to choose which method we’d like to use to avoid valuable information missing."
  },
  {
    "objectID": "clustering/clustering1.html#footnotes",
    "href": "clustering/clustering1.html#footnotes",
    "title": "Clustering",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n“K-Means Clustering.” Wikipedia, Wikimedia Foundation, 12 Oct. 2023, en.wikipedia.org/wiki/K-means_clustering.↩︎\n“DBSCAN.” Wikipedia, Wikimedia Foundation, 27 Oct. 2023, en.wikipedia.org/wiki/DBSCAN.↩︎\n“Hierarchical Clustering.” Wikipedia, Wikimedia Foundation, 10 Oct. 2023, en.wikipedia.org/wiki/Hierarchical_clustering.↩︎"
  },
  {
    "objectID": "decision_trees/tree.html",
    "href": "decision_trees/tree.html",
    "title": "Decision Tree & Random Forest",
    "section": "",
    "text": "A tree structure that describes instance classification is called a classification decision tree model. The nodes and directed edges create a decision tree. Inner nodes and leaf nodes are the two distinct types of nodes. Leaf nodes indicate a class, while internal nodes represent as a feature or attribute. A decision tree, additionally referred to as a binary or multinomial tree, is a predictive analytical model displayed as a tree structure.\nOne way to classify instances is to arrange them from a root node to a leaf node. The classifications to which the examples belong are called leaf nodes. Every node in the tree represents a test of an instance attribute, and every branch that follows the node represents a potential attribute value.\n\n\n\nCreate a randomized forest with a large number of decision trees that are unrelated to one another. When a new input sample enters the forest after it has been obtained, every decision tree in the forest makes an assessment to determine which category (for classification algorithms) the sample should belong to. It then determines which category is more frequently selected, allowing the sample to be predicted for that category. Decision trees, which are essentially a method of partitioning space into hyperplanes and halving the current space each time, make up a random forest. Basically Random Forest are composite by many decision tree.\n\n\n\nFor my dataset of Mobile phones, I used deciosion tree to do the classification. Based on the mobile phone prices, the function ratings of the mobile phone, for example, the camera rating, display rating, battery rating, etc. Based on those data, the decision tree model should predict the label of whether the public is willing to buy or not. The predicted label was devided into birnary classfication, not willing and very willing. the decison tree model will give the final result."
  },
  {
    "objectID": "decision_trees/tree.html#train-tree-model",
    "href": "decision_trees/tree.html#train-tree-model",
    "title": "Decision Tree & Random Forest",
    "section": "Train Tree Model",
    "text": "Train Tree Model\n\n#### INSERT CODE BELOW TO TRAIN A SKLEARN DECISION TREE MODEL ON x_train,y_train \nfrom sklearn import tree\nmodel = tree.DecisionTreeClassifier()\nmodel = model.fit(x_train, y_train)\n\n\n# INSERT CODE TO USE THE MODEL TO MAKE PREDICTIONS FOR THE TRAINING AND TEST SET \nyp_train = model.predict(x_train)\nyp_test = model.predict(x_test)\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\n\nfrom sklearn.metrics import confusion_matrix\n\ndef confusion_plot(Y_test, Y_pred):\n    matrix = confusion_matrix(Y_test, Y_pred)\n    accuracy = accuracy_score(Y_test, Y_pred)\n    precision_1 = precision_score(Y_test, Y_pred, pos_label = 1)\n    recall_1 = recall_score(Y_test, Y_pred, pos_label = 1)\n    precision_0= precision_score(Y_test, Y_pred, pos_label = 0)\n    recall_0 = recall_score(Y_test, Y_pred, pos_label = 0)\n    print(\"ACCURACY: \", accuracy)\n    print(\"NEGATIVE RECALL (Y=0): \",recall_0 )\n    print(\"NEGATIVE PRECISION (Y=0):\",precision_0) \n    print(\"POSITIVE RECALL (Y=1):\",recall_1) \n    print(\"POSITIVE PRECISION (Y=1):\", precision_1)\n    print(matrix)\n    plt.figure(figsize=(5, 4))\n    sns.heatmap(matrix, annot=True, fmt='d', cmap='YlGnBu', cbar=True)\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label')\n    plt.show()\n\n\nresult\n\n# RUN THE FOLLOWING CODE TO TEST YOUR FUNCTION \nprint(\"------TRAINING------\")\nconfusion_plot(y_train,yp_train)\nprint(\"------TEST------\")\nconfusion_plot(y_test,yp_test)\n\n------TRAINING------\nACCURACy:  1.0\nNEGATIVE RECALL (Y=0):  1.0\nNEGATIVE PRECISION (Y=0): 1.0\nPOSITIVE RECALL (Y=1): 1.0\nPOSITIVE PRECISION (Y=1): 1.0\n[[88  0]\n [ 0 34]]\n------TEST------\nACCURACy:  0.967741935483871\nNEGATIVE RECALL (Y=0):  1.0\nNEGATIVE PRECISION (Y=0): 0.9375\nPOSITIVE RECALL (Y=1): 0.9375\nPOSITIVE PRECISION (Y=1): 1.0\n[[15  0]\n [ 1 15]]\n\n\n\n\n\n\n\n\n\n\nVisualize Tree\n\n# INSERT CODE TO WRITE A FUNCTION \"def plot_tree(model,X,Y)\" VISUALIZE THE DECISION TREE (see https://mljar.com/blog/visualize-decision-tree/ for an example)\nfrom sklearn import tree\ndef plot_tree(model,X,Y):\n    fig = plt.figure(figsize=(25,20))\n    _ = tree.plot_tree(model, \n                    filled=True)\n    plt.show()\nplot_tree(model,X,Y)\n\n\n\n\n\n\nAnalysis\nBased on the training result, ACCURACY: 1.0, NEGATIVE RECALL (Y=0): 1.0, NEGATIVE PRECISION (Y=0): 1.0, POSITIVE RECALL (Y=1): 1.0, POSITIVE PRECISION (Y=1): 1.0, The accuracy, negative recall, negative precision, positive recall, positive precision are all 100%, which shows the training result can 100% predict the label, which is an awesome performance. Thus the model for the training set perform well.\nBased on the test result: ACCURACY: 0.967741935483871, NEGATIVE RECALL (Y=0): 1.0, NEGATIVE PRECISION (Y=0): 0.9375, POSITIVE RECALL (Y=1): 0.9375, POSITIVE PRECISION (Y=1): 1.0, Accuracy is 0.9677 and accuracy measures the overall correctness of a classification model. 96.77% means the model is not 100% correctly predicted the data, which may needs a little imporve. The negative recall and precision is 1 which mean 100% right, which means it perform well. The native precision measures the accuracy of the model when it predicts the negative class (class 0), and the sore is 0.9375, which may needs improve. The positive recall measures the ability of the model to correctly identify instances belonging to the positive class (class 1), and the score is 0.9375, so this may needs a little imporvement as well.\nThus for better fit in the model, I did a hyper-parameter Turning to see if there’s better model paramter to fit in."
  },
  {
    "objectID": "decision_trees/tree.html#result",
    "href": "decision_trees/tree.html#result",
    "title": "label modfication to binary",
    "section": "result",
    "text": "result\n\n# RUN THE FOLLOWING CODE TO TEST YOUR FUNCTION \nprint(\"------TRAINING------\")\nconfusion_plot(y_train,yp_train)\nprint(\"------TEST------\")\nconfusion_plot(y_test,yp_test)\n\n------TRAINING------\nACCURACy:  1.0\nNEGATIVE RECALL (Y=0):  1.0\nNEGATIVE PRECISION (Y=0): 1.0\nPOSITIVE RECALL (Y=1): 1.0\nPOSITIVE PRECISION (Y=1): 1.0\n[[88  0]\n [ 0 34]]\n------TEST------\nACCURACy:  0.967741935483871\nNEGATIVE RECALL (Y=0):  1.0\nNEGATIVE PRECISION (Y=0): 0.9375\nPOSITIVE RECALL (Y=1): 0.9375\nPOSITIVE PRECISION (Y=1): 1.0\n[[15  0]\n [ 1 15]]"
  },
  {
    "objectID": "decision_trees/tree.html#visualize-tree",
    "href": "decision_trees/tree.html#visualize-tree",
    "title": "label modfication to binary",
    "section": "Visualize Tree",
    "text": "Visualize Tree\n\n# INSERT CODE TO WRITE A FUNCTION \"def plot_tree(model,X,Y)\" VISUALIZE THE DECISION TREE (see https://mljar.com/blog/visualize-decision-tree/ for an example)\nfrom sklearn import tree\ndef plot_tree(model,X,Y):\n    fig = plt.figure(figsize=(25,20))\n    _ = tree.plot_tree(model, \n                    filled=True)\n    plt.show()\nplot_tree(model,X,Y)"
  },
  {
    "objectID": "decision_trees/tree.html#train-optimal-model",
    "href": "decision_trees/tree.html#train-optimal-model",
    "title": "Decision Tree & Random Forest",
    "section": "Train optimal model",
    "text": "Train optimal model\n\n#### COMPLETE THE CODE BELOW TO TRAIN A SKLEARN DECISION TREE MODEL ON x_train,y_train \nfrom sklearn import tree\nmodel = tree.DecisionTreeClassifier(max_depth=3)\nmodel = model.fit(x_train, y_train)\n\nyp_train=model.predict(x_train)\nyp_test=model.predict(x_test)\n\n\n# RUN THE FOLLOWING CODE TO EVALUATE YOUR MODEL\nprint(\"------TRAINING------\")\nconfusion_plot(y_train,yp_train)\nprint(\"------TEST------\")\nconfusion_plot(y_test,yp_test)\n\nplot_tree(model,X,Y)\n\n------TRAINING------\nACCURACy:  1.0\nNEGATIVE RECALL (Y=0):  1.0\nNEGATIVE PRECISION (Y=0): 1.0\nPOSITIVE RECALL (Y=1): 1.0\nPOSITIVE PRECISION (Y=1): 1.0\n[[88  0]\n [ 0 34]]\n------TEST------\nACCURACy:  0.967741935483871\nNEGATIVE RECALL (Y=0):  1.0\nNEGATIVE PRECISION (Y=0): 0.9375\nPOSITIVE RECALL (Y=1): 0.9375\nPOSITIVE PRECISION (Y=1): 1.0\n[[15  0]\n [ 1 15]]\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis\nBased on the training and test result, the optimal result is actually the result we had interpreted before. Thus when the the tree’s layers=3, the model reach the optimal status and give us the test score as shown: ACCURACY: 0.967741935483871, NEGATIVE RECALL (Y=0): 1.0, NEGATIVE PRECISION (Y=0): 0.9375, POSITIVE RECALL (Y=1): 0.9375, POSITIVE PRECISION (Y=1): 1.0,\nEven though the score are not all 100%, the accuracy, negative precision,and positive recall are all higher than 90%, they are good enough to prove the model perform well to predict the label."
  },
  {
    "objectID": "decision_trees/tree.html#split-data",
    "href": "decision_trees/tree.html#split-data",
    "title": "Decision Tree & Random Forest",
    "section": "Split data",
    "text": "Split data\n\n# INSERT CODE TO PARTITION THE DATASET INTO TRAINING AND TEST SETS\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n\nprint(\"X TRAINING SHAPES:\",x_train.shape)\nprint(\"Y TRAINING SHAPES:\",y_train.shape)\nprint(\"X TEST SHAPES:\",x_test.shape)\nprint(\"Y TEST SHAPES:\",y_test.shape)\n\nX TRAINING SHAPES: (122, 6)\nY TRAINING SHAPES: (122,)\nX TEST SHAPES: (31, 6)\nY TEST SHAPES: (31,)"
  },
  {
    "objectID": "decision_trees/tree.html#random-forest-training",
    "href": "decision_trees/tree.html#random-forest-training",
    "title": "Decision Tree & Random Forest",
    "section": "Random Forest training",
    "text": "Random Forest training\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nmodel = RandomForestClassifier(random_state=42)\nmodel = model.fit(x_train, y_train)\n\nyp_train = model.predict(x_train)\nyp_test = model.predict(x_test)"
  },
  {
    "objectID": "decision_trees/tree.html#result-1",
    "href": "decision_trees/tree.html#result-1",
    "title": "Decision Tree & Random Forest",
    "section": "Result",
    "text": "Result\n\n# RUN THE FOLLOWING CODE TO TEST YOUR FUNCTION \nprint(\"------TRAINING------\")\nconfusion_plot(y_train,yp_train)\nprint(\"------TEST------\")\nconfusion_plot(y_test,yp_test)\n\n------TRAINING------\nACCURACy:  1.0\nNEGATIVE RECALL (Y=0):  1.0\nNEGATIVE PRECISION (Y=0): 1.0\nPOSITIVE RECALL (Y=1): 1.0\nPOSITIVE PRECISION (Y=1): 1.0\n[[88  0]\n [ 0 34]]\n------TEST------\nACCURACy:  0.967741935483871\nNEGATIVE RECALL (Y=0):  1.0\nNEGATIVE PRECISION (Y=0): 0.9375\nPOSITIVE RECALL (Y=1): 0.9375\nPOSITIVE PRECISION (Y=1): 1.0\n[[15  0]\n [ 1 15]]\n\n\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\ntree.plot_tree(model.estimators_[0],\n               filled = True);\nfig.savefig('rf_individualtree.png')\n\n\n\n\n\nAnalysis\nBased on the training result, ACCURACY: 1.0, NEGATIVE RECALL (Y=0): 1.0, NEGATIVE PRECISION (Y=0): 1.0, POSITIVE RECALL (Y=1): 1.0, POSITIVE PRECISION (Y=1): 1.0, The accuracy, negative recall, negative precision, positive recall, positive precision are all 100%, which shows the training result can 100% predict the label, which is an awesome performance. Thus the model for the training set perform well.\nBased on the test result: ACCURACY: 0.967741935483871, NEGATIVE RECALL (Y=0): 1.0, NEGATIVE PRECISION (Y=0): 0.9375, POSITIVE RECALL (Y=1): 0.9375, POSITIVE PRECISION (Y=1): 1.0, Accuracy is 0.9677 and accuracy measures the overall correctness of a classification model. 96.77% means the model is not 100% correctly predicted the data, which may needs a little imporve. The negative recall and precision is 1 which mean 100% right, which means it perform well. The native precision measures the accuracy of the model when it predicts the negative class (class 0), and the sore is 0.9375, which may needs improve. The positive recall measures the ability of the model to correctly identify instances belonging to the positive class (class 1), and the score is 0.9375, so this may needs a little imporvement as well.\nThus for better fit in the model, I did a hyper-parameter Turning to see if there’s better model paramter to fit in."
  },
  {
    "objectID": "decision_trees/tree.html#hyperparameter-tuning",
    "href": "decision_trees/tree.html#hyperparameter-tuning",
    "title": "Decision Tree & Random Forest",
    "section": "Hyperparameter Tuning",
    "text": "Hyperparameter Tuning\n\n# COMPLETE THE FOLLOWING CODE TO LOOP OVER POSSIBLE HYPER-PARAMETERS VALUES\ntest_results=[]\ntrain_results=[]\n\nfor num_layer in range(1,10):\n    model = RandomForestClassifier(max_depth=num_layer)\n    model = model.fit(x_train, y_train)\n\n    yp_train=model.predict(x_train)\n    yp_test=model.predict(x_test)\n\n    # print(y_pred.shape)\n    test_results.append([num_layer,accuracy_score(y_test, yp_test),recall_score(y_test, yp_test,pos_label=0),recall_score(y_test, yp_test,pos_label=1)])\n    train_results.append([num_layer, accuracy_score(y_train, yp_train), recall_score(y_train, yp_train, pos_label = 0), recall_score(y_train, yp_train, pos_label = 1)])\n\n\n# INSERT CODE TO GENERATE THE THREE PLOTS BELOW (SEE EXPECTED OUTPUT FOR EXAMPLE)\n\n# NOTE: THERE IS A TYPO IN THE THIRD PLOT, IT SHOULD BE RECALL IN THE Y-AXIS LABEL NOT ACCURACY\ntrain_df = pd.DataFrame(train_results, columns = ['max_depth', 'accuracy', 'recall_negative', 'recall_positive'])\ntest_df = pd.DataFrame(test_results, columns = ['max_depth', 'accuracy', 'recall_negative', 'recall_positive'])\n\nplt.plot(train_df['max_depth'], train_df['accuracy'], 'o-', color = 'blue', label = 'Train Accuracy')\nplt.plot(test_df['max_depth'], test_df['accuracy'], 'o-', color = 'red', label = 'Test Accuracy')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('Accuracy (Y = 0): Training (blue) and Test (red)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nplt.plot(train_df['max_depth'], train_df['recall_negative'], 'o-', color = 'blue', label = 'Train Negative Recall')\nplt.plot(test_df['max_depth'], test_df['recall_negative'], 'o-', color = 'red', label = 'Test Negative Recall')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('Recall (Y = 0): Training (blue) and Test (red)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nplt.plot(train_df['max_depth'], train_df['recall_positive'], 'o-', color = 'blue', label = 'Train Positive Recall')\nplt.plot(test_df['max_depth'], test_df['recall_positive'], 'o-', color = 'red', label = 'Test Positive Recall')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('Recall (Y = 0): Training (blue) and Test (red)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIn the Hype-parameter above, I let the model iterate between different depth of decision tree and then use the random forest model to fit in and try to find the optimal layers of decision tree and then form the which gives the highest accuracy and recall score, and this shows the optimal paramater for this random forest. Based on the graph 1 above, we can see that when the layer reach 2 both the train and test accuracy can reach 100% and the score line become flat, even when the layers numbers become higher, the model performance is not improving. Same situation appear in the both recall score plot. So, after depth=2, the model may become a little overfitting. Thus, we can conclude that when the depth=2, the model is optimal. Next we will use this optimal depth."
  },
  {
    "objectID": "decision_trees/tree.html#train-optimal",
    "href": "decision_trees/tree.html#train-optimal",
    "title": "Decision Tree & Random Forest",
    "section": "Train Optimal",
    "text": "Train Optimal\n\n#### COMPLETE THE CODE BELOW TO TRAIN A SKLEARN DECISION TREE MODEL ON x_train,y_train \nfrom sklearn import tree\nmodel = RandomForestClassifier(max_depth=2)\nmodel = model.fit(x_train, y_train)\n\nyp_train=model.predict(x_train)\nyp_test=model.predict(x_test)\n\n\n# RUN THE FOLLOWING CODE TO EVALUATE YOUR MODEL\nprint(\"------TRAINING------\")\nconfusion_plot(y_train,yp_train)\nprint(\"------TEST------\")\nconfusion_plot(y_test,yp_test)\n\n------TRAINING------\nACCURACy:  0.9918032786885246\nNEGATIVE RECALL (Y=0):  0.9886363636363636\nNEGATIVE PRECISION (Y=0): 1.0\nPOSITIVE RECALL (Y=1): 1.0\nPOSITIVE PRECISION (Y=1): 0.9714285714285714\n[[87  1]\n [ 0 34]]\n------TEST------\nACCURACy:  0.967741935483871\nNEGATIVE RECALL (Y=0):  1.0\nNEGATIVE PRECISION (Y=0): 0.9375\nPOSITIVE RECALL (Y=1): 0.9375\nPOSITIVE PRECISION (Y=1): 1.0\n[[15  0]\n [ 1 15]]\n\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\ntree.plot_tree(model.estimators_[0],\n               filled = True);\nfig.savefig('rf_individualtree.png')\n\n\n\n\n\nAnalysis\nThe accuracy score, negative recall and positive Precision score are not 100% for the test set. The accuracy score, negative precision, and positive precision score are not 100% of the training set as well. However, they all passed 90%, which are good enogh to prove the model perform well to predict the label."
  },
  {
    "objectID": "decision_trees/tree.html#split-train-set-and-test-set",
    "href": "decision_trees/tree.html#split-train-set-and-test-set",
    "title": "Decision Tree & Random Forest",
    "section": "split train set and test set",
    "text": "split train set and test set\n\n# INSERT CODE TO PARTITION THE DATASET INTO TRAINING AND TEST SETS\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n\nprint(\"X TRAINING SHAPES:\",x_train.shape)\nprint(\"Y TRAINING SHAPES:\",y_train.shape)\nprint(\"X TEST SHAPES:\",x_test.shape)\nprint(\"Y TEST SHAPES:\",y_test.shape)\n\nX TRAINING SHAPES: (122, 6)\nY TRAINING SHAPES: (122,)\nX TEST SHAPES: (31, 6)\nY TEST SHAPES: (31,)"
  },
  {
    "objectID": "decision_trees/tree.html#hyper-parameter-turning",
    "href": "decision_trees/tree.html#hyper-parameter-turning",
    "title": "Decision Tree & Random Forest",
    "section": "Hyper-parameter Turning",
    "text": "Hyper-parameter Turning\n\n# COMPLETE THE FOLLOWING CODE TO LOOP OVER POSSIBLE HYPER-PARAMETERS VALUES\ntest_results=[]\ntrain_results=[]\n\nfor num_layer in range(1,10):\n    model = tree.DecisionTreeClassifier(max_depth=num_layer)\n    model = model.fit(x_train, y_train)\n\n    yp_train=model.predict(x_train)\n    yp_test=model.predict(x_test)\n\n    # print(y_pred.shape)\n    test_results.append([num_layer,accuracy_score(y_test, yp_test),recall_score(y_test, yp_test,pos_label=0),recall_score(y_test, yp_test,pos_label=1)])\n    train_results.append([num_layer, accuracy_score(y_train, yp_train), recall_score(y_train, yp_train, pos_label = 0), recall_score(y_train, yp_train, pos_label = 1)])\n\n\n# INSERT CODE TO GENERATE THE THREE PLOTS BELOW (SEE EXPECTED OUTPUT FOR EXAMPLE)\n\n# NOTE: THERE IS A TYPO IN THE THIRD PLOT, IT SHOULD BE RECALL IN THE Y-AXIS LABEL NOT ACCURACY\ntrain_df = pd.DataFrame(train_results, columns = ['max_depth', 'accuracy', 'recall_negative', 'recall_positive'])\ntest_df = pd.DataFrame(test_results, columns = ['max_depth', 'accuracy', 'recall_negative', 'recall_positive'])\n\nplt.plot(train_df['max_depth'], train_df['accuracy'], 'o-', color = 'blue', label = 'Train Accuracy')\nplt.plot(test_df['max_depth'], test_df['accuracy'], 'o-', color = 'red', label = 'Test Accuracy')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('Accuracy (Y = 0): Training (blue) and Test (red)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nplt.plot(train_df['max_depth'], train_df['recall_negative'], 'o-', color = 'blue', label = 'Train Negative Recall')\nplt.plot(test_df['max_depth'], test_df['recall_negative'], 'o-', color = 'red', label = 'Test Negative Recall')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('Recall (Y = 0): Training (blue) and Test (red)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nplt.plot(train_df['max_depth'], train_df['recall_positive'], 'o-', color = 'blue', label = 'Train Positive Recall')\nplt.plot(test_df['max_depth'], test_df['recall_positive'], 'o-', color = 'red', label = 'Test Positive Recall')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('Recall (Y = 0): Training (blue) and Test (red)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIn the Hype-parameter above, I let the model iterate between different depth of decision tree and try to find the optimal layers of decision which gives the highest accuracy and recall score. Based on the graph 1 above, we can see that when the layers=3 both the train and test accuracy can reach 100%. When the layers numbers become higher, the model show a little overfitting. Based on the graph2, we also can see that when the layers=3 both the train and test accuracy can reach 100%. When the layers numbers become higher, the model’s performance did not improve. Thus, we can conclude that when the depth=3, the model is optimal. Next we will use this optimal depth."
  },
  {
    "objectID": "decision_trees/tree.html#decision-tree",
    "href": "decision_trees/tree.html#decision-tree",
    "title": "Decision Tree & Random Forest",
    "section": "",
    "text": "A tree structure that describes instance classification is called a classification decision tree model. The nodes and directed edges create a decision tree. Inner nodes and leaf nodes are the two distinct types of nodes. Leaf nodes indicate a class, while internal nodes represent as a feature or attribute. A decision tree, additionally referred to as a binary or multinomial tree, is a predictive analytical model displayed as a tree structure.\nOne way to classify instances is to arrange them from a root node to a leaf node. The classifications to which the examples belong are called leaf nodes. Every node in the tree represents a test of an instance attribute, and every branch that follows the node represents a potential attribute value."
  },
  {
    "objectID": "decision_trees/tree.html#random-forest",
    "href": "decision_trees/tree.html#random-forest",
    "title": "Decision Tree & Random Forest",
    "section": "",
    "text": "Create a randomized forest with a large number of decision trees that are unrelated to one another. When a new input sample enters the forest after it has been obtained, every decision tree in the forest makes an assessment to determine which category (for classification algorithms) the sample should belong to. It then determines which category is more frequently selected, allowing the sample to be predicted for that category. Decision trees, which are essentially a method of partitioning space into hyperplanes and halving the current space each time, make up a random forest. Basically Random Forest are composite by many decision tree."
  },
  {
    "objectID": "decision_trees/tree.html#apply-to-the-dataset",
    "href": "decision_trees/tree.html#apply-to-the-dataset",
    "title": "Decision Tree & Random Forest",
    "section": "",
    "text": "For my dataset of Mobile phones, I used deciosion tree to do the classification. Based on the mobile phone prices, the function ratings of the mobile phone, for example, the camera rating, display rating, battery rating, etc. Based on those data, the decision tree model should predict the label of whether the public is willing to buy or not. The predicted label was devided into birnary classfication, not willing and very willing. the decison tree model will give the final result."
  },
  {
    "objectID": "data_gathering/data_gathering.html#main-goal",
    "href": "data_gathering/data_gathering.html#main-goal",
    "title": "Data Gathering",
    "section": "",
    "text": "For this project, the main point is finding people’s attitude towards Apple Products and evaluate what kind of mobile products would attract the public to purchase. Thus I need to find both text data to reflect people’s attitude towards Apple Products and record data to evaluate the products’ popularity and people’s buying willingness. Thus, I need search online to find either people’s comments towards Apple Products or the news’ reports related to Apple products. Also, I need to find some dataset to evaluate what kinds of mobile products that would be popular in the market, so when the new generation of Apple Products come out we can predict the new products’ popularity."
  },
  {
    "objectID": "data_gathering/data_gathering.html#dataset-finding",
    "href": "data_gathering/data_gathering.html#dataset-finding",
    "title": "Data Gathering",
    "section": "",
    "text": "News API: Gathering news’ reports to reflect the public attitudes towards Apple products.\nNews Webpage: Collect more news reports to reflect the public attitudes\nWeibo: Crawl comments from the social media to see the users’ reaction to the new Apple Products\nYahoo! Finance: collect Apple’s recent stock performance and this also can reflect the apple products’ popularity.\nMobile phone ratings: trying to find a dataset that have ratings related to all different functions of the mobile phones and what their popularity with the mobile phones."
  },
  {
    "objectID": "data_gathering/data_gathering.html#tools-using",
    "href": "data_gathering/data_gathering.html#tools-using",
    "title": "Data Gathering",
    "section": "",
    "text": "Python\nR\nNews API\nDownloading Dataset"
  },
  {
    "objectID": "data_gathering/data_gathering.html#data-gathering-1",
    "href": "data_gathering/data_gathering.html#data-gathering-1",
    "title": "Data Gathering",
    "section": "",
    "text": "Python, Web crawl\nDataset Collecrion: Weibo is a Chinese social platform that Chinese public sharing thoughts and post articles. There are 52 illion daily active users via that social media.I crawled data from Weibo to catch some hot posts about people’s reaction to the new publishion of Apple products. Most of the articles relected strong sentiments towards the products\nweibo data gathering code (python)\nraw data for weibo(python)\nsample raw data \nDataset Exaplaination: From the view of dataset, this is a text dataset and we can see the users’ ID and the publish dates and also the contents and commens(in Chinese).\n\n\n\n\n\nPython, News API\nDataset Collection: crawl data by using NewsAPI with Python and try to extract some key words from the news. The news API can help me to find the most updated articles related to the topics I am trying to search and based on the contens, I can analyze those text to see what’s the attitude of media towards the iPhone.\nNews data gathering code (python)\nraw data for newsAPI(python)\nsample raw data \nDataset Exaplaination: As shown above, this is a text dataset and we can read all the articles that News API collected.\n\n\n\n\n\nR, Rvest\nDataset Collection: Revest is also an useful tool to help up to crawl conetent from the website we want. I used Rvest to craw text with R and get content from the news website I selected.\nNews webpage data gathering code (R)\nraw data for news webpage(R)\nsample raw data \nDataset Exaplaination: as shown in above, as shown above, this is also a text dataset and we can read all the articles that Rvest collected.\n\n\n\n\n\nDownloading from Yahoo! Finance\nDataset Collection: Stock price and trend also can reflect the company’s popularity and how the public’s attitude towards the company. Thus I downloaded the Apple stock’s recent stock price and trying to analyze its stock trend.\nDataset source: Apple Stock in Yahoo! Finance\nsample raw data \nDataset Explaination: As shown in the dataset, this is a record dataset. We can see there’s the date, Openprice, highest price, lowest Price, close price, and trading volume. Based on this dataset, for nect next step we can analyze its stock prices changes.\n\n\n\n\n\nCollecting from Dxomark\nDataset collection: The dataset that evaluate the functions for a mobile phone can help me to identify the public’s buying willingness to the product. Thus I collected the dataset from the DXOMARK website that reflect the device’s performance and the quality of the user experience.\nDataset source: DXOMARK smartphone reviews\nsample raw data \nDataset Explaination: As shown in the dataset, this is a record dataset. The dataset has its ranking and devices’ name, its Launch price, Launche date, camera rating, selfie rating, audio rating, display rating and battery ratings. All those ratings are important factors that impact the customers’ buying inetent. Thus this dataset will help me to predict wether a smartphone product will be popular based on the ratings.\n\n\n\n\nIn this part, I collected 5 different datasets that related to my research topic, Apple Products’ Popularity. The datasets are including text data and record data. The methods I used to collect data are using news API, crawling data with Python, Rvest with R, and downloading related data directly from the website.\nNext step I will clean and modified the data as need for preparing for the future model training."
  },
  {
    "objectID": "index.html#topics-introduction",
    "href": "index.html#topics-introduction",
    "title": "DSAN-5000: Introduction",
    "section": "Topics Introduction",
    "text": "Topics Introduction\n\nsummary\nOver the decades, Apple’s products are always the most popular products in the markets. However, with more and more new products introduced to the market. Is Apple products, especially iphone, are still popular in the market?\nImportance\nThe iPhone has significantly influenced technology and culture since its introduction in 2007. It has influenced and impacted a genration, thus everyone curious about how apple performed in the recent years. Its role in shaping consumer behaviors, communication norms, and mobile technology makes it a rich subject for study.\nWhy the reader should continue\nThe choices and preferences of iPhone users can reflect broader trends in consumer behavior. Consumers can pick better products through this research topic and see how consumers react to Apple’s products.\nwhat work had done\nThe researchers had done many data collection, data preprocessing, and set up machine learning models to do the logistic regression, decision trees and random forest, etc. They also had done so many behavioral analysis to analyze the popularity trend for electronic products.\nwhat are the “different points of views”/interpretations in the literature\nSome literature emphasizes Apple’s commitment to innovation and high-quality products as a key factor in its popularity. This view holds that the company’s focus on design, user experience, and robust performance drives consumer preference. Some authors also discuss Apple’s cultural impact, suggesting that its products have become more than just technology but a part of modern culture.\nwhat exploring:\n\nWe can explore how people evaluate an electronic products as a good products.\nWe can explore the stock market for the Apple Products and how it stock prices changes\nWe can collect customers’ review/news on Apple products, to see how everyone like apple’s products.\n\ngoals and hypothesis\nclean the data I collect and find some factors that impact the financial fraud and make a fraud detetction model."
  },
  {
    "objectID": "index.html#next-steps",
    "href": "index.html#next-steps",
    "title": "DSAN-5000: Introduction",
    "section": "Next Steps:",
    "text": "Next Steps:\nTo complete this research topic, I need to find datasets and related information related to people’s reviews that reflect people’s actual reaction related to Apple brands and iPhone Products. Also, I need to find some datasets that can help me to research what kind of quality of functions that would attract a customer to purchase. Whether Apple products perform well in those functions area?\nAfter I collected the datasets, I need to clean them as needed and prepare for the future model use and data analysis process."
  },
  {
    "objectID": "data_cleaning/data_cleaning.html#main-goal",
    "href": "data_cleaning/data_cleaning.html#main-goal",
    "title": "Data Cleanning",
    "section": "",
    "text": "The purpose of data cleansing is to remove data noise points by eliminating erroneous, duplicate parts of the data. In this part, I will do a statictal analysis first to identify the dataset’s mean, variance, frenquency, etc. From this step, we can find the datasets’ noise points and clean them as needed. For the record data, most data cleaning process will dealing with the abnormal values, fill null values and remove missing values, etc. For the text data, most data cleaning process will dealing with cleaning the stop words, removing white spaces, etc."
  },
  {
    "objectID": "data_cleaning/data_cleaning.html#main-methods-for-data-cleaning",
    "href": "data_cleaning/data_cleaning.html#main-methods-for-data-cleaning",
    "title": "Data Cleanning",
    "section": "Main Methods For Data Cleaning",
    "text": "Main Methods For Data Cleaning\nRecord Data\n\nfill null values: There are always missing values in the reocrd dataset, thus we need to decide whether we should remove the null values or fill the null values. Most times, we can use the mean/median to fill the null value based on the dataset itself.\nremove duplicates: Usually the dataset may have same entries and that will affect our future data analysis, thus we should remove them as needed in case impact the results.\nhandling outliers: Some data point are obviously different than others, thus we need to think whether that was recorded by mistake and unuseful to the data analysis, and considering remove them.\nconvert data types: when same data type did not match as it should to be, we can convert them to the data types we need to use for future data analysis. eg: string -&gt; int\n\nText Data\n\nRemove stop words: the stop words like “the, and, an” are not useful for the text analysis, so we need to remove them as needed.\nRemove special characters and punctuation: the special characters like “$ @ %” are not useful for the text analysis, so we need to remove them as needed.\nTokenization: we can split text data into sentences or words for better analyzation.\nStemming and Lemmatization: in English, the verbs or nouns usually have different forms but actually has the same means, so we need to do this step for better analyze the text data.\nRemove white spaces: Sometimes the white spaces or new lines will hinder the analysis process, so we should clean it"
  },
  {
    "objectID": "data_cleaning/data_cleaning.html#data-cleaning",
    "href": "data_cleaning/data_cleaning.html#data-cleaning",
    "title": "Data Cleanning",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\nClean the NewsAPI Raw Data (gather by Python)\n\nPython\nExplaination: the iphone_content.txt is a text data, so I will clean the raw data with the motheods dealing with text data.\nraw data before cleaning \nnewsapi data cleaning code (python)\n\nCleaning Process\n\nimport needed packages: will use sklearn, json, re, pandas, etc\n\n\nRemove the special characters, lower cases, and remove white spaces: In this part, it will remove unnecessary punctations, spaces and also lower the capitalized cases.\n\n\n\nCode\ndef string_cleaner(input_string):\n    try: \n        '''\n        out=re.sub(r\"\"\"\n                    [,;@#&$-]+  # Accept one or more copies of punctuation\n                    \\ *           # plus zero or more copies of a space,\n                    \"\"\",\n                    \" \",          # and replace it with a single space\n                    input_string, flags=re.VERBOSE)\n        '''\n\n        #REPLACE SELECT CHARACTERS WITH NOTHING\n        out = re.sub('[’]+', '', input_string)\n\n        #ELIMINATE DUPLICATE WHITESPACES USING WILDCARDS\n        out = re.sub(r'\\s+', ' ', out)\n\n        #CONVERT TO LOWER CASE\n        out=out.lower()\n    except:\n        print(\"ERROR\")\n        out=''\n    return out\n\n\n\nLemitization: In this part, lemitization will reduce a word to its base or root form, which will help me analyze this dataset.\nstemming: in this part, stemming will remove affixes from words, which will help me analyze this dataset.\nword tokenize: in this part, tokenize will split the sentences to words, which will help me analyze this dataset.\nremove stopwords: in this part, removing stopwords will keep more valueble words for analysis.\nCountvectorizer: in this part, countvectorizer will help me to count how many times each word appears in the library, which will help in analyze the word frequency.\n\nAfter cleaning process, below is the after cleaning dataset\n\ncleaned data for newsapi(python)\noutput cleaning data \n\n\n\nclean the weibo hot post data (gather by Python)\n\nR\nExplaination: 微博清单.csv is a text data, I will clean this raw data with R, and reordered the dataset, dropped unnecessary columns/rows, and cleaned the text part by segmentation and clear stop words, etc.\nraw data before cleaning \nweibo data cleaning code (R)\n\nCleaning Process\n\nchange the column orders: in this step, reorganize the column will help me easier find more useful information\ncheck duplicated and drop duplicated rows: checked the duplicated rows but there isn’t any.\nreordered the dataframe by the descending order of the like numbers column: the like numbers reflect whether this comment is hot or not, so when the numbers are larger, the more influencial this comment will be.\ndrop unnecessary columns: the ‘id’ column is not useful for the data analysis, so I droped this column.\ndrop unnecessary rows: I deleted the posts’ likes numbers &lt;3, and keep popular post with post’s like number &gt;3, because they are more useful content\nsegment the content: segment the sentences into words\ncleaned stop words in the post content: removing stopwords will keep more valueble words for analysis.\n\nAfter cleaning process, below is the after cleaning dataset\n\ncleaned data for weibo(R)\noutput cleaning data \n\n\n\nClean the Mobile Phone Rating Dataset\n\nPython\nExplaination: mobile_phone_rating.csv is a record dataset, so I will clean the raw data with the motheods dealing with record data.\nraw data before cleaning \nmobile phone cleaning code (R)\n\nCleaning Process\n\nreplace ‘-’ and null to ‘0’: the raw dataset are all string type, and ‘-’ represents null values, change to 0 will be easier for future change column type\nchange the column’s type: change most columns that with numbers to int type and ‘Launch date’ column to date type.\nfill missing values: in this step, I choose to fill null values with each column’s average value\ncheck nulls: check if there’s still exist null values\ncreate label: create label based on the ‘Rank’ column for future machine learning training\ndrop unnecessray column: drop the ‘Rank’ column because it’s unnecessary for now\nshuffle the dataset: because the dataset was ordered by the rank, and I want the dataset not in a specific order for future model training\n\nAfter cleaning process, below is the after cleaning dataset * cleaned data for mobile phone rating\n\noutput cleaning data \n\n\n\nApple Stock Dataset\n\nThis dataset is clean and organized as needed, so skipped the cleaning process"
  },
  {
    "objectID": "data_cleaning/data_cleaning.html#next-step",
    "href": "data_cleaning/data_cleaning.html#next-step",
    "title": "Data Cleanning",
    "section": "Next step",
    "text": "Next step\nFor this part, I cleaned both record data and text data with necessary methods. All the datasets are cleaned as needed and ready for the exploratory data analysis and model training. Next step, I will do some EDA to familiar with our dataset and functions of them and this will help me to visualize the data as well."
  },
  {
    "objectID": "dimensionality_reduction/reduction.html#dimensionality-introduction",
    "href": "dimensionality_reduction/reduction.html#dimensionality-introduction",
    "title": "Dimensionality Reduction",
    "section": "Dimensionality introduction",
    "text": "Dimensionality introduction\nIn the field of machine learning, the dimensionality reduction refers to the use of some kind of projection method to project the data points in the original high-dimensional space to a lower dimensional space. By dimensionality reduction, we can reduce the error caused by redundant information and imporve the accuracy of recognition. Now, dimensionality has become part of data preparation process for future model training. Following are some main methods of dimensionality reduction.\nPrinciple Component Analysis (PCA)\nPrinciple Component Analysis are commonly used linear dimensionality reduction method. One of ts goal is to use less data dimension that most can repensent the original dataset’s characteristics by using some linear projection from high-dimension data into low-dimension data, in the mean while maximize the variance of the data being projected. Here’s a simple example expalining this concept. For example, if you want to organize some photos of people, and the two characteristics you really care about is the race and gender. When trying to reorganize the photos, your shoud find what matters to you most, and reorganize the photos by the order of characteristics you focus more on, and then creating the new display of those photos. So this is how PCA works. Following are some main process we doing PCA:\n\nStandardization\nCovariance Matrix Computation\nEigenvectors and Eigenvalues\nChoosing Principal Components\nTransforming Data\n\nt-SNE\nt-Distributed Stochastic Neighbor Embedding is a non-linear dimensionality reduction method that used to form high-dimensional data in a low-dimensional environment. Our goal is to reduce the amount of complicated, multi-dimensional data regarding neighboring points (the “neighborhood”) to a more manageable format, akin to what a distribution would use to express it. Method: Using these data points, we’ll model a random walk. Moving toward a nearby site during this process is more likely than to occur at a distant one. Lastly, we locate points in a space that is smaller in dimension. The neighborhood pattern around these locations ought to be very similar to the initial high-dimensional neighborhood distribution. 1"
  },
  {
    "objectID": "dimensionality_reduction/reduction.html#tools",
    "href": "dimensionality_reduction/reduction.html#tools",
    "title": "Dimensionality Reduction",
    "section": "Tools",
    "text": "Tools\nIn this part, the library will include json, numpy, pandas, matplotlib, scikit-learn, sklearn.manifold.TSNE, etc."
  },
  {
    "objectID": "conclusion/conclusion.html#project-goal",
    "href": "conclusion/conclusion.html#project-goal",
    "title": "Conclusion",
    "section": "",
    "text": "The goal for this project is identify whether Apple products are still popular in the market, and find out public’s reaction to Apples’ new products. Also, I want to find out what kind of of quality of a mobile phone should have that will attract the public to buy. Thus, I should train some models that can predict a product’s populariy based on its functions, so when iPhone’s new generation came out, I can use thid model to predict its popularity."
  },
  {
    "objectID": "conclusion/conclusion.html#data-analysis-result",
    "href": "conclusion/conclusion.html#data-analysis-result",
    "title": "Conclusion",
    "section": "",
    "text": "In this part, I collected 3 text datasets and 2 record datasets by using API, Web Crawling, downloading methods by using Python and R. Most text datasets are related to the public’s reviews and comments towards Apple products,and one of the record datasets are related to Apple stock, and another is related to the mobile phones’ function rating. All the datasets can help me to dig into this research topic.\nHere’s some sample raw datasets:\nraw text data \nraw record data \n\n\n\nIn this part, I did data cleanning process for the datasets that I needed for preparing for future data analysis and model training. For the record data, I did fill null values, remove duplicates, handling outliers, convert data types, etc cleaning process. For the text data, I did remove stop words, remove special characters and punctuation, tokenization, stemming and lemmatization, remove white spaces, etc cleaning process.\nHere’s some sample cleaned datasets:\ncleaned text data \ncleaned record data \n\n\n\nIn this part, I did some exploratory data analysis for the cleaned datasets for better knowing the datasets. I used visualization tools to help the audience know more about my project, which will include text clouds, statistic distribution, correlation heatmap, etc.\nHere are some examples: \nHere’s some key words that appeared most frequently in the news dataset that I collected. As we can see, most words are natural and positive towards apple products.\n\n\n\nopen price for apple stock\n\n\nFrom the Apple stock’s plot we can see from the past year, the stock price is in the increasing trend, which means more poeple are willing to buy Apple’s stock, which means Apple is still popular in the market.\n\n\n\nTop 50 Ranking Brands\n\n\nAs shown in the pie chart, in the Top 50 ranking phones, 20% are apples. Which means there are 10 iphones are ranked in top50. This also shows Apple is still one of the most popular brands in the market.\n\n\n\nIn this part, I used K-means, DBSAN, Hierarchical clustering methods to clustered the mobile phone ratings dataset. Based on the hyperparameter turning, here’s the optimal clusters results: K-means: 2 DBSCAN : 4 Agglomerative Hierarchy: 2 Meanshift : 4 Birch : 3\nBased on the analysis process, I think Agglomerative Hierarchy would the best method for this dataset, and the optimal clustering would be 2.\n\n\n\nAgglomerative Hierarchy Clustering\n\n\n\n\n\nIn this part, I used PCA and t-SNE method to reduce the dimension for better analyzing the mobile phone ratings dataset. Based on the visualization result, I believe PCA would be a better method for this dataset.\n\n\n\nPCA\n\n\nAs shown in the graph, the red line intersect the blue line at number of comonents around = 4. So, when the number of compnents is larger than 4 which is 5, we can make 95% variance expliained. There for we should reduce the number of components to 5."
  },
  {
    "objectID": "conclusion/conclusion.html#model-training",
    "href": "conclusion/conclusion.html#model-training",
    "title": "Conclusion",
    "section": "",
    "text": "In this part, I used decision tree and random forest to do the classification. I training the model based on the mobile phone prices, the function ratings of the mobile phones to predict the public’s the buying intent to the products. - Decision Tree The optimal levels are 3\n\n\n\nDecision tree\n\n\nAnd the final test showed the model performed well: ACCURACY: 0.967741935483871 NEGATIVE RECALL (Y=0): 1.0 NEGATIVE PRECISION (Y=0): 0.9375 POSITIVE RECALL (Y=1): 0.9375 POSITIVE PRECISION (Y=1): 1.0 \n\nRandom Forest The result for the random forst is similar to the decision tree, and I believe the decision tree is better predict the model. More content related to random forest can be found in the Decision Tree Tab.\n\n\n\n\nIn this part, I used Naive Bayes algorithmn predict the lebels for the mobile phone ratings dataset and also the news text dataset. I used feature selection of variance thredhold method with hyperparameter tuning for better training the model.\nFinal result showed the naive bayes predicted my record dataset well. \n\n\n\nConfusion Metrics\n\n\nFinal result also showed the naive bayes predicted my text dataset well.\n\n\n\nEvaluation Metrics\n\n\n\n\n\nConfusion Metrics\n\n\nMore analysis can find in the Naive Bayes tab."
  },
  {
    "objectID": "conclusion/conclusion.html#questions-answers",
    "href": "conclusion/conclusion.html#questions-answers",
    "title": "Conclusion",
    "section": "",
    "text": "Based on the research above, I belive I can explain all the questions listed in the introduction well:\n\nCan customer reviews and sentiment analysis on social media reflect the public’s reaction to the products?\nYes, based on the sentiment analysis and key words extraction, we can see the public’s reaction easily.\nHow does Apple’s stock performed? Apple stock performed well in the past year.\nWhat are the trends in iPhone stocks sale volume over the last decade? the sale volumn are not increasing that much which may be a good signal for the current shareholder.\nWhat kind of electronic products can be seem as a good product to buy? higher in price, higher in the selfie, audio, etc functions ratings.\nHow does the pricing of Apple products compare with competitors over time, and what is the impact on market share and consumer choice? Apple’s product are kind of higher than the other competitors’ products\nHow can we predict whether Apple’s products would be popular in the future? From its function ratings, we can predict whether the public willing to buy or not.\nCan we use machine learning to identify key factors that predict an Apple product’s popularity based on historical data? Yes, based on the correlation map, we can see the price and selfie function are highly corelated and impacted the products’ popularity\nWhat kind of models we can used to predict people’s attitude with reviews? we can use the naive bayes or decision tree model to predict\nCan decision tree analysis help in identifying whether a product is a successful mobile phone product? Yes, we can use decision tree actually is the best method to predict the label.\nHow can we eliminate the unnecessary feature for predicting the Apple’s products? We can use some feature selection methods, like variance thredhold to eliminate some features."
  },
  {
    "objectID": "conclusion/conclusion.html#conclusion-1",
    "href": "conclusion/conclusion.html#conclusion-1",
    "title": "Conclusion",
    "section": "",
    "text": "From this project, we can know more about the public’s review and reaction on apple products and how to predict a new generation iphone’s popularity. From all the research above, I can conclude that Apple products are still popular in the market, and people’s reviews are more in postive way. The Apple stock price also reflect the popularity of Apple brand. Also the ratings of apple products are still very high compare to other brands.\nThus, apple products are still very popular and worthy to buy based on its functionality ratings. We can also use those ratings based on machine learning models to predict the popularity of future products.\nThanks for going over this project!"
  }
]